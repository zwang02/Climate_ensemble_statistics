{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_Ziwei_Ensemble_release.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrP5PnLraxHh"
      },
      "source": [
        "# Workflow: Processing raw data to pandas DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PxJOca1av-Y"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xarray as xr\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "import scipy.stats as stats\n",
        "import seaborn as sns\n",
        "xr.set_options(display_style='html')\n",
        "\n",
        "# To install netCDF4 for .nc files (does not come pre-loaded in CO)\n",
        "!pip install netCDF4\n",
        "from netCDF4 import Dataset\n",
        "import netCDF4\n",
        "\n",
        "import IPython\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "\n",
        "\n",
        "### To mount google drive in runtime to access files in the drive so you can access files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "home_dir = '/content/drive/My Drive/100yr-Ensemble-Data/Spatial-and-Annual-Averages/'\n",
        "gnu_dir = home_dir+'GNU-runs/'\n",
        "intel_dir = home_dir+'Intel-runs/'\n",
        "test_dir = home_dir+'Test-runs/'\n",
        "\n",
        "### Use local directory to save a copy to your folder\n",
        "local_dir = '/content/drive/My Drive/Ensemble_project/'\n",
        "\n",
        "# Set tot True if we want to drop Intel Simulation 115\n",
        "drop_115 = True\n",
        "drop_000 = True\n",
        "get_data = False\n",
        "remove_var = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWcJbSsu3QDR"
      },
      "source": [
        "# Credits to Curtis\n",
        "def approx_z_cleaning(input_df,my_var,threshold):\n",
        "  #std_temp = np.std(input_variable)\n",
        "  #mean_temp = np.mean(input_variable)\n",
        "  low_percentile = input_df[my_var].quantile(0.025)\n",
        "  high_percentile = input_df[my_var].quantile(0.975)\n",
        "  variable_mid = input_df[(input_df[my_var] > low_percentile) & (input_df[my_var] < high_percentile)][my_var]\n",
        "  mean_mid = variable_mid.mean()\n",
        "  std_mid = variable_mid.std()\n",
        "  if std_mid != 0:\n",
        "    reduced_var = (input_df[my_var] - mean_mid)/std_mid\n",
        "    bad_data_flags = reduced_var[np.abs(reduced_var) > threshold].index\n",
        "  return bad_data_flags\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0ezvRVXbwz3"
      },
      "source": [
        "var_df = pd.read_csv(local_dir+'CESM_variable_type.csv')\n",
        "var_df['my_type'] = var_df['type']\n",
        "var_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7j_7__OjZgTs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ2TGUcxCnOq"
      },
      "source": [
        "In total 114 Intel simulations, throw Intel.115 as it is compromised. Throw Intel.006 due to wrong SNOWHICE. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM8xNbzpXVxL"
      },
      "source": [
        "### Start empty DataFrame here\n",
        "if get_data:\n",
        "  df = pd.DataFrame()\n",
        "\n",
        "  ### Append all data into this DataFrame\n",
        "  for my_dir, my_label in zip([gnu_dir,intel_dir,test_dir],['GNU','Intel','Test']):\n",
        "    for filename in os.listdir(my_dir):\n",
        "      if filename.endswith(\"nc\"): \n",
        "          print(filename)\n",
        "          simulation = filename.split('.')[-2]\n",
        "          print(simulation)\n",
        "          ds = xr.open_dataset(my_dir+filename)\n",
        "          newdf = ds.to_dataframe()\n",
        "          newdf = newdf.reset_index(level=[0,1])\n",
        "          newdf['varNames'] = newdf['varNames'].str.decode(\"utf-8\")\n",
        "\n",
        "\n",
        "          newdf = newdf.pivot_table(index = ['nyear'],columns=['varNames'],values=['spatialAvgs'])\n",
        "          newdf.columns = newdf.columns.droplevel(0)\n",
        "          # Label the simulations with 'GNU','Intel', or 'Test'\n",
        "          newdf['Label'] = my_label\n",
        "          newdf['Simulation'] = str(simulation)\n",
        "          newdf = newdf.reset_index()\n",
        "          df = df.append(newdf,ignore_index = True)\n",
        "  df.Simulation = df.Simulation.astype(str)\n",
        "  if drop_115:\n",
        "    df.drop(index = df[(df.Label == 'Intel') & (df.Simulation.str.contains('115'))].index,inplace = True)\n",
        "  if drop_000:\n",
        "    df.drop(index = df[(df.Label == 'Intel') & (df.Simulation.str.contains('000'))].index,inplace = True)\n",
        "  \n",
        "  df.to_csv(local_dir+'ensemble_all.csv')\n",
        "\n",
        "else:\n",
        "  df = pd.read_csv(local_dir+'ensemble_all.csv')\n",
        "  df = df.drop(axis=1,columns=['Unnamed: 0'])\n",
        "  #df[df.TS < 280] = np.nan\n",
        "  df['Simulation'] = [str(my_str).zfill(3) for my_str in df['Simulation']]\n",
        "  if drop_115:\n",
        "    df.drop(index = df[(df.Label == 'Intel') & (df.Simulation.str.contains('115'))].index,inplace = True)\n",
        "  if drop_000:\n",
        "    df.drop(index = df[(df.Label == 'Intel') & (df.Simulation.str.contains('000'))].index,inplace = True)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WsBZWYntIT4"
      },
      "source": [
        "Evolution of distribution across simulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwGoLL60_ewA"
      },
      "source": [
        "Credit to (partially): https://stackoverflow.com/questions/58786611/plotly-two-subplots-controlled-by-one-slider"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdiJXzHYtHoZ"
      },
      "source": [
        "import plotly.figure_factory as ff\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "\n",
        "# Add histogram data\n",
        "my_var = 'BURDEN2'\n",
        "intel_df = df[(df.Label == 'Intel')]\n",
        "my_test_input = 'rh-min-low'\n",
        "nsteps = 10\n",
        "fig = go.Figure()\n",
        "\n",
        "gnu_df = df[df.Label == 'GNU']\n",
        "\n",
        "\n",
        "\n",
        "def make_interact_dist(my_var,nsteps,my_test = my_test_input):\n",
        "  init_year = 0\n",
        "  test_df = df[df.Simulation == my_test]\n",
        "  mean_init_intel = intel_df[intel_df.nyear == init_year].mean()[my_var]\n",
        "  std_init_intel = intel_df[intel_df.nyear == init_year].std()[my_var]\n",
        "  mean_init_gnu = gnu_df[gnu_df.nyear == init_year].mean()[my_var]\n",
        "  std_init_gnu = gnu_df[gnu_df.nyear == init_year].std()[my_var]\n",
        "  fig = make_subplots(rows=1, cols=1,shared_xaxes=True)#, subplot_titles = ['Mean %f' % (mean_init_intel) +', Std %f' % (std_init_intel),'Mean %f' % (mean_init_gnu) +', Std %f' % (std_init_gnu)]\n",
        "\n",
        "\n",
        "  #xmin = np.nanmin((intel_df.min()[my_var],gnu_df.min()[my_var]))\n",
        "  #xmax = np.nanmax((intel_df.max()[my_var],gnu_df.max()[my_var]))\n",
        "\n",
        "  xmin = np.nanmin((intel_df.min()[my_var],gnu_df.min()[my_var],test_df.min()[my_var]))\n",
        "  xmax = np.nanmax((intel_df.max()[my_var],gnu_df.max()[my_var],test_df.max()[my_var]))\n",
        "  nbins = 40\n",
        "  bin_size = (xmax - xmin)/nbins\n",
        "  xbins = np.linspace(xmin,xmax,nbins+1)\n",
        "\n",
        "  print(xmin,xmax,np.percentile((xmin,xmax),80))\n",
        "  intel_ymax = []\n",
        "  gnu_ymax = []\n",
        "  intel_mean = []\n",
        "  intel_std = []\n",
        "  gnu_mean = []\n",
        "  gnu_std = []\n",
        "  for step in np.arange(0, nsteps, 1):\n",
        "    my_year = step\n",
        "    \n",
        "    x1 = np.array(intel_df[intel_df.nyear == my_year][my_var])\n",
        "    x2 = np.array(gnu_df[gnu_df.nyear == my_year][my_var])\n",
        "    #x3 = np.array(test_df[test_df.nyear == my_year][my_var])    \n",
        "\n",
        "\n",
        "    # Create distplot with custom bin_size\n",
        "    #fig = ff.create_distplot(hist_data, group_labels)#, bin_size=[.05, 0.05]\n",
        "    counts_intel, bins = np.histogram(x1,bins = xbins,density =True)\n",
        "    counts_gnu, bins = np.histogram(x2,bins = xbins,density =True)\n",
        " \n",
        "    counts_intel = counts_intel/np.sum(counts_intel)\n",
        "    counts_gnu = counts_gnu/np.sum(counts_gnu)\n",
        "    intel_ymax.append(counts_intel)\n",
        "    gnu_ymax.append(counts_intel)\n",
        "    intel_mean.append(x1.mean())\n",
        "    intel_std.append(x1.std())\n",
        "    gnu_mean.append(x2.mean())\n",
        "    gnu_std.append(x2.std())\n",
        "  ### Decide ymax\n",
        "  ymax_intel = np.nanmax(intel_ymax)\n",
        "  ymax_gnu = np.nanmax(gnu_ymax)   \n",
        "  ymax = np.nanmax([ymax_intel,ymax_gnu]) \n",
        "  print(intel_std)\n",
        "\n",
        "  for step in np.arange(0, nsteps, 1):\n",
        "    my_year = step\n",
        "    \n",
        "    x1 = np.array(intel_df[intel_df.nyear == my_year][my_var])\n",
        "    x2 = np.array(gnu_df[gnu_df.nyear == my_year][my_var])\n",
        "    x3 = np.array(test_df[(df.Simulation == my_test) & (df.nyear == my_year)][my_var])[0]\n",
        "    fig.add_trace(go.Histogram(visible=False,x=x1, histnorm='probability',name = 'Intel',xbins=dict(\n",
        "                      start=xmin,\n",
        "                      end=xmax,\n",
        "                      size=bin_size), \n",
        "                      autobinx=False\n",
        "                     ),row=1, col=1)\n",
        "    \n",
        "    fig.add_trace(go.Histogram(visible=False,x=x2, histnorm='probability',name = 'GNU',xbins=dict(\n",
        "                      start=xmin,\n",
        "                      end=xmax,\n",
        "                      size=bin_size), \n",
        "                      autobinx=False\n",
        "                     ),row=1, col=1)\n",
        "    #fig.add_annotation(\n",
        "    #          visible = False,\n",
        "    #          x=np.percentile((xmin,xmax),20),\n",
        "    #          y=ymax_intel*0.95,\n",
        "    #          text=\"Mean: %f\" % ((x1.mean())),\n",
        "    #          showarrow= False\n",
        "    #  )\n",
        "    #fig.add_annotation(\n",
        "    #          visible = False,\n",
        "    #          x=np.percentile((xmin,xmax),20),\n",
        "    #          y=ymax_intel*0.8,\n",
        "    #          text=\"Std: %f\" % ((x1.std())),\n",
        "    #          showarrow= False\n",
        "    #  )\n",
        "\n",
        "    fig.add_trace(go.Scatter(visible=False,x=[x3, x3], y=[0,ymax], \n",
        "      mode=\"lines\",name = my_test, line=dict(color=\"black\",dash='dash') ),row=1,col=1)\n",
        "    fig.add_trace(go.Scatter(visible=False,x=[x1.mean(), x1.mean()], y=[0,ymax], \n",
        "      mode=\"lines\",name = 'Mean Intel',line=dict(color=\"blue\",dash='dash') ),row=1,col= 1)\n",
        "    fig.add_trace(go.Scatter(visible=False,x=[x2.mean(), x2.mean()], y=[0,ymax], \n",
        "      mode=\"lines\",name = 'Mean GNU',line=dict(color=\"red\",dash='dash') ),row=1,col= 1)\n",
        "        \n",
        "    fig.update_traces(opacity=0.75)\n",
        "    \n",
        "\n",
        "    #fig['layout']['annotations'][0].update(text='Mean %f' % (x1.mean()) +', Std %f' % (x1.std()))\n",
        "    #fig['layout']['annotations'][1].update(text='Mean %f' % (x2.mean()) +', Std %f' % (x2.std()))\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  fig.data[0].visible = True\n",
        "  fig.data[1].visible = True\n",
        "  fig.data[2].visible = True\n",
        "  fig.data[3].visible = True\n",
        "  fig.data[4].visible = True\n",
        "\n",
        "  #fig.layout.annotations[0].visible = False\n",
        "  #fig.layout.annotations[1].visible = False\n",
        "\n",
        "  # Create and add slider\n",
        "  years = []\n",
        "  \n",
        "  for i in range(0, len(fig.data), 5):\n",
        "      year = dict(\n",
        "          method=\"update\",\n",
        "          label = 'Year {}'.format(int(i/5)+1),\n",
        "          args=[{\"visible\": [False] * len(fig.data)},\n",
        "                {\"title\": \"Distribution across ensemble for year \" + str(int(i/5)+1)},\n",
        "                {\"annotation\": ['Mean %f' % my_mean for my_mean in (intel_mean)]}\n",
        "                ],  # layout attribute\n",
        "      )\n",
        "      year[\"args\"][0][\"visible\"][i] =True  # Toggle i'th trace to \"visible\"\n",
        "      year[\"args\"][0][\"visible\"][i+1] =True  # Toggle i'th trace to \"visible\"\n",
        "      year[\"args\"][0][\"visible\"][i+2] =True  # Toggle i'th trace to \"visible\"\n",
        "      year[\"args\"][0][\"visible\"][i+3] =True  # Toggle i'th trace to \"visible\"\n",
        "      year[\"args\"][0][\"visible\"][i+4] =True  # Toggle i'th trace to \"visible\"\n",
        "      #for new_idx in range(len(fig.layout.annotations)):\n",
        "      #  fig.layout.annotations[new_idx].visible = False\n",
        "\n",
        "      years.append(year)\n",
        "\n",
        "  sliders = [dict(\n",
        "      active=0,\n",
        "      currentvalue={\"prefix\": \"This is \"},\n",
        "      pad={\"t\": nsteps},\n",
        "      steps=years\n",
        "  )]\n",
        "\n",
        "  fig.update_layout(\n",
        "      sliders=sliders\n",
        "  )\n",
        "\n",
        "  fig.update_xaxes(range=[xmin, xmax])\n",
        "  fig.update_yaxes(range=[0, ymax*1.1],row=1,col=1)\n",
        "  #fig.update_yaxes(range=[0, ymax_gnu*1.2],row=2,col=1)\n",
        "\n",
        "\n",
        "  fig.show()\n",
        "\n",
        "  return fig\n",
        "my_fig = make_interact_dist(my_var = 'SNOWHLND',nsteps = 10,my_test = 'rh-min-low')\n",
        "my_fig.write_html(local_dir+\"/interactive_distribution.html\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2dqteCcNpao"
      },
      "source": [
        "Throw away outliers with 95% in middle: Z values should be smaller than 7-sigma. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDEc9WkBNyKE"
      },
      "source": [
        "A good test with BURDEN2, first year should be thrown away."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIbFBEzaHUrH"
      },
      "source": [
        "#var = var_list[90]\n",
        "remove_outlier = True\n",
        "df_clean = df.copy()\n",
        "\n",
        "my_ens = 'Intel'\n",
        "my_var = 'BURDEN2'\n",
        "simu_list = np.unique(df_clean[df_clean.Label == my_ens]['Simulation'])\n",
        "for simu in simu_list:\n",
        "  input_df = df_clean[(df_clean.Label == my_ens) & (df_clean.Simulation == simu)]\n",
        "  test_loc = approx_z_cleaning(input_df,my_var,10)\n",
        "  if remove_outlier:\n",
        "    #print(test_loc)\n",
        "    df_clean[(df_clean.Label == my_ens) & (df_clean.Simulation == simu)].loc[test_loc][my_var] = np.nan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmdXxGOEHV3S"
      },
      "source": [
        "newdf = df[(df.Label == 'GNU') & (df.Simulation == '001')]\n",
        "newdf.iloc[0].BURDEN2/newdf[1:100].BURDEN2.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etfCnzyIPp4r"
      },
      "source": [
        "df_clean[df_clean['BURDEN2'].isnull()]#['BURDEN2']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtn30Y5GqhgQ"
      },
      "source": [
        "def enable_plotly_in_cell():\n",
        "    display(IPython.core.display.HTML('''<script src=\"/static/components/requirejs/require.js\"></script>'''))\n",
        "    init_notebook_mode(connected=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JewnuoJSZnuw"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O34_xt0CFmC4"
      },
      "source": [
        "### STATS figure for Liz, 2020/09\n",
        "fs = 14\n",
        "sns.set_context(\"paper\", rc={\"font.size\":14,\"axes.titlesize\":14,\"axes.labelsize\":14})   \n",
        "\n",
        "fig = plt.figure(1,figsize=(10,8))\n",
        "newdf = df[df.Label.isin(['Intel','GNU'])]\n",
        "b = sns.lineplot(x = 'nyear',y = 'TS',data = newdf, hue = 'Label', ci = 95)\n",
        "\n",
        "b.tick_params(labelsize=fs-2)\n",
        "#b.set_xlabel(fontsize=fs-2)\n",
        "\n",
        "\n",
        "fig = plt.figure(2,figsize = (8,6))\n",
        "my_var = 'TS'\n",
        "my_year = 0\n",
        "df_x = df[(df.Label == 'Intel') & (df.nyear == my_year)]\n",
        "df_y = df[(df.Label == 'GNU') & (df.nyear == my_year)]\n",
        "res = stats.ks_2samp(np.array(df_y[my_var]),np.array(df_x[my_var]))\n",
        "\n",
        "bins = np.linspace(np.nanmin([df_x[my_var].min(),df_y[my_var].min()]),np.nanmax([df_x[my_var].max(),df_y[my_var].max()]),20)\n",
        "plt.hist(df_x[my_var], bins=bins, density=True, histtype='step', cumulative=True,\n",
        "        label='Intel',lw=2)\n",
        "plt.hist(df_y[my_var], bins=bins, density=True, histtype='step', cumulative=True,\n",
        "        label='GNU',lw=2)\n",
        "plt.title('nyear: {my_year}, ks-pvalue: {pval}'.format(my_year= my_year,pval = round(res[1],2)))\n",
        "plt.legend(loc = 2,frameon=False,fontsize = fs-2)\n",
        "plt.xlabel('TS (K)',fontsize = fs-2)\n",
        "plt.ylabel('CDF',fontsize = fs-2)\n",
        "plt.xticks(fontsize = fs-2)\n",
        "plt.yticks(fontsize = fs-2)\n",
        "plt.locator_params(nbins=5)\n",
        "print('KS-statistics: ',res)\n",
        "\n",
        "\n",
        "fig = plt.figure(3,figsize = (8,6))\n",
        "my_var = 'TS'\n",
        "my_year = 63\n",
        "df_x = df[(df.Label == 'Intel') & (df.nyear == my_year)]\n",
        "df_y = df[(df.Label == 'GNU') & (df.nyear == my_year)]\n",
        "res = stats.ks_2samp(np.array(df_y[my_var]),np.array(df_x[my_var]))\n",
        "\n",
        "bins = np.linspace(np.nanmin([df_x[my_var].min(),df_y[my_var].min()]),np.nanmax([df_x[my_var].max(),df_y[my_var].max()]),20)\n",
        "plt.hist(df_x[my_var], bins=bins, density=True, histtype='step', cumulative=True,\n",
        "        label='Intel',lw=2)\n",
        "plt.hist(df_y[my_var], bins=bins, density=True, histtype='step', cumulative=True,\n",
        "        label='GNU',lw=2)\n",
        "plt.title('nyear: {my_year}, ks-pvalue: {pval}'.format(my_year= my_year,pval = round(res[1],2)))\n",
        "plt.legend(loc = 2,frameon=False, fontsize = fs-2)\n",
        "plt.xlabel('TS (K)',fontsize = fs-2)\n",
        "plt.ylabel('CDF',fontsize = fs-2)\n",
        "plt.xticks(fontsize = fs-2)\n",
        "plt.yticks(fontsize = fs-2)\n",
        "plt.locator_params(nbins=5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVlb41UfFj5t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC02bB-NAisd"
      },
      "source": [
        "# Workflow: Visualization with pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcOK0Xz2A0E3"
      },
      "source": [
        "Pick several random Intel runs: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnPHTHKhgP3J"
      },
      "source": [
        "### Take 5 random simulation numbers to be shown\n",
        "rand = np.random.randint(0,115,5)\n",
        "rand_list = [str(my_rand).zfill(3) for my_rand in rand]\n",
        "rand_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgEYfuH0BFj1"
      },
      "source": [
        "my_df = df.copy()\n",
        "#print(my_df)\n",
        "my_df['Simulation'] = my_df['Simulation'].astype(str)\n",
        "print(\"1\\n\",my_df)\n",
        "my_df = my_df[(my_df.Label == 'Intel') & (my_df['Simulation'].isin(rand_list))]\n",
        "print(\"2\\n\",my_df)\n",
        "my_df = my_df.melt(id_vars=['nyear','Simulation'],value_vars=['TS'])\n",
        "print(\"3\\n\",my_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5YU9yngPI3-"
      },
      "source": [
        "miss_df = df[df.isnull().any(axis=1)]\n",
        "for col,my_bool in zip(df.columns,(df[df.isnull().any(axis=1)].isnull().any(axis=0))):\n",
        "  if my_bool:\n",
        "    print('A missing value appear for: ',col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnpNyCrWH-cC"
      },
      "source": [
        "miss_df[['nyear','Label','Simulation','TS','AODVIS','CCN3','ICWMR','SNOWHICE','VD01','VV','ncl_a1_SRF']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIssSqWeZXtK"
      },
      "source": [
        "#import seaborn as sns\n",
        "#sns.lineplot(x=\"nyear\", y=\"value\", data=my_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkNHpG1Xy2s1"
      },
      "source": [
        "### An animation of heatmap."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI668SL6pR4u"
      },
      "source": [
        "newdf = df[df.Label == 'GNU']\n",
        "run_list = np.unique(newdf['Simulation'].astype(float))\n",
        "nrun = len(run_list)\n",
        "col_df = newdf.drop(axis=1,columns=['nyear','Label','Simulation'])\n",
        "# Remove constant columns\n",
        "#col_df = col_df.loc[:,col_df.apply(pd.Series.nunique) != 1]\n",
        "column_list = col_df.columns\n",
        "ncol = len(column_list)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uck5GoE-5GlE"
      },
      "source": [
        "Which variables do not change across the ensemble? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4hNbNiY4WuY"
      },
      "source": [
        "removed_column_list = list(column_list)\n",
        "# Remove three variables with bump start: 'OCNFRAC','ICEFRAC','SNOWHICE'\n",
        "# Remove three constant variables: 'LANDFRAC','PHIS','SOLIN'\n",
        "#remove_var_list =  ['EMISCLD','OCNFRAC','ICEFRAC','LANDFRAC','PHIS','SOLIN']\n",
        "remove_var_list =  ['H2O2_SRF','DTWR_H2O2','OCNFRAC','ICEFRAC','LANDFRAC','PHIS','SOLIN','EMISCLD'] #SNOWHLND\n",
        "\n",
        "for my_col in remove_var_list:\n",
        "  removed_column_list.remove(my_col)\n",
        "np.array(removed_column_list,dtype=str)\n",
        "col_list = column_list.copy()\n",
        "\n",
        "#if remove_var:\n",
        "#  column_list = removed_column_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icvp5sgHSXQI"
      },
      "source": [
        "import scipy.stats as stats\n",
        "gb = df[(df.Label == 'Intel')].groupby('nyear')\n",
        "z_list = []\n",
        "for my_var in removed_column_list:\n",
        "  #my_var = removed_column_list[0]\n",
        "  x = df[(df.Label == 'Intel') & (df.nyear == 0)][my_var].std()\n",
        "  dist = gb[my_var].std()\n",
        "  if dist.std() > 0:\n",
        "    zscore = (x - dist.mean())/dist.std()\n",
        "    print(zscore)\n",
        "    if abs(zscore) > 3:\n",
        "      print(my_var)\n",
        "    z_list.append(zscore)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "086HQvLzgwDT"
      },
      "source": [
        "plt.hist(z_list)\n",
        "z_list = np.array(z_list)\n",
        "len(z_list[z_list < 0])*1./len(z_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhjPUTg2xjpv"
      },
      "source": [
        "#### Each variable\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhuJr_rixmGr"
      },
      "source": [
        "'''\n",
        "from plotly.offline import init_notebook_mode, iplot, plot\n",
        "import plotly.graph_objs as go  \n",
        "\n",
        "enable_plotly_in_cell()\n",
        "\n",
        "var_df = newdf.pivot_table(values = ['T'],index = ['nyear'],columns = ['Simulation'])\n",
        "# remove outliers\n",
        "fig = go.Figure(data=go.Heatmap(\n",
        "                    z=var_df))\n",
        "\n",
        "\n",
        "fig.update_layout(\n",
        "    showlegend = True,\n",
        "    width = 700, height = 700,\n",
        "    autosize = False,xaxis_title=\"Simulations\",yaxis_title=\"Years\" )\n",
        "fig.show()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAb_dBpIpEOF"
      },
      "source": [
        "#### Z score (mean and standard deviation)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOL-RrkgpJDT"
      },
      "source": [
        "We can also assume a Gaussian distribution and fit each dataset to it. Then we can plot mean and standard deviation. \n",
        "\n",
        "Each year, use 114 Intel simulation as whole distribution, plot test runs Z-value. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP4DVFp3ORqN"
      },
      "source": [
        "'''\n",
        "from scipy.stats import norm\n",
        "import scipy.stats as stats\n",
        "\n",
        "my_ensemble = 'Intel'\n",
        "my_var = 'TS'\n",
        "year_list = np.arange(0,100,1)\n",
        "nyear = len(year_list)\n",
        "\n",
        "col_df = newdf\n",
        "ncol = len(col_df.columns)\n",
        "all_z_matrix = np.zeros((nyear,ncol,nrun))\n",
        "simu_list = np.unique(df[df.Label == my_ensemble]['Simulation'])\n",
        "\n",
        "mean_list = np.zeros(nyear)\n",
        "std_list = np.zeros(nyear)\n",
        "#mean_matrix = np.zeros((ncol,nyear))\n",
        "#std_matrix = np.zeros((ncol,nyear))\n",
        "for iz,my_simu in enumerate(simu_list):\n",
        "  z_df = df[(df.Label == my_ensemble) & (df.Simulation == my_simu)]\n",
        "  #z_df = df[(df.Label == my_ensemble)]\n",
        "  for iy, col in enumerate(col_df.columns):\n",
        "    x = z_df[[col]]\n",
        "    #y = newdf[column_list[iy]]\n",
        "    mask = np.isfinite(x) #& np.isfinite(y)\n",
        "    mu, std = norm.fit(x[mask])\n",
        "    mean_list[ix] = mu\n",
        "    #mean_matrix[ix,iy] = mu*1./std\n",
        "    std_list[ix] = std\n",
        "    #std_matrix[ix,iy] = std\n",
        "\n",
        "    for ix, year in enumerate(year_list):\n",
        "      all_z_matrix[ix,iy,iz] = (df[(df.Label == my_ensemble) & (df.nyear == year) & (df.Simulation == my_simu)][my_var] - mu)/std*1.\n",
        "\n",
        "# Now test with another dataset\n",
        "#test_df = df[df.Label == 'GNU']\n",
        "intel_df =df[df.Label == 'Intel']\n",
        "gnu_dg = df[df.Label == 'GNU'] \n",
        "test_df = df[df.Label == 'Test']\n",
        "test_list=np.unique(test_df.Simulation)\n",
        "ntest = len(test_list)\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-cewMN8UXUu"
      },
      "source": [
        "df['ANRAIN'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1hnm_jBtP-d"
      },
      "source": [
        "### Plot the all z-values\n",
        "'''\n",
        "print(np.shape(all_z_matrix))\n",
        "enable_plotly_in_cell()\n",
        "\n",
        "print('This is heatmap of 8 test runs, ',my_var)\n",
        "print('Testing against ',my_ensemble)\n",
        "fig = go.Figure(data=go.Heatmap(\n",
        "                    z=all_z_matrix[:,0,:],x = test_list))\n",
        "\n",
        "fig.update_layout(\n",
        "    showlegend = True,\n",
        "    width = 700, height = 700,\n",
        "    autosize = False,xaxis_title=\"Test runs \",yaxis_title=\"Years\" )\n",
        "fig.show()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFPlxuKRT-Yd"
      },
      "source": [
        "Now for each ensemble (GNU,Intel) show z value for each test run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqDXLM2ypUlY"
      },
      "source": [
        "from scipy.stats import norm\n",
        "import scipy.stats as stats\n",
        "\n",
        "my_ensemble = 'GNU'\n",
        "my_var = 'TS'\n",
        "year_list = np.arange(0,100,1)\n",
        "nyear = len(year_list)\n",
        "\n",
        "col_df = newdf[[my_var]]\n",
        "ncol = len(col_df.columns)\n",
        "all_z_matrix = np.zeros((nyear,ncol,nrun))\n",
        "simu_list = np.unique(df[df.Label == my_ensemble]['Simulation'])\n",
        "\n",
        "mean_list = np.zeros(nyear)\n",
        "std_list = np.zeros(nyear)\n",
        "#mean_matrix = np.zeros((ncol,nyear))\n",
        "#std_matrix = np.zeros((ncol,nyear))\n",
        "for ix, year in enumerate(year_list):\n",
        "  z_df = df[(df.Label == my_ensemble) & (df.nyear == year)]\n",
        "  #z_df = df[(df.Label == my_ensemble)]\n",
        "  for iy, col in enumerate(col_df.columns):\n",
        "    x = z_df[col]\n",
        "    #y = newdf[column_list[iy]]\n",
        "    mask = np.isfinite(x) #& np.isfinite(y)\n",
        "    mu, std = norm.fit(x[mask])\n",
        "    mean_list[ix] = mu\n",
        "    #mean_matrix[ix,iy] = mu*1./std\n",
        "    std_list[ix] = std\n",
        "    #std_matrix[ix,iy] = std\n",
        "\n",
        "\n",
        "# Now test with another dataset\n",
        "#test_df = df[df.Label == 'GNU']\n",
        "intel_df =df[df.Label == 'Intel']\n",
        "gnu_dg = df[df.Label == 'GNU'] \n",
        "test_df = df[df.Label == 'Test']\n",
        "test_list=np.unique(test_df.Simulation)\n",
        "ntest = len(test_list)\n",
        "\n",
        "#print(test_df)\n",
        "z_matrix = np.zeros((nyear,ntest))\n",
        "p_matrix = np.zeros((nyear,ntest))\n",
        "for itest in range(ntest):\n",
        "  for iyear in range(nyear):\n",
        "    newdf = test_df[(test_df.nyear == year_list[iyear]) & (test_df.Simulation == test_list[itest])]\n",
        "    if len(newdf) == 1:\n",
        "      z_matrix[iyear,itest] = (newdf[my_var] - mean_list[iyear]) / std_list[iyear]\n",
        "      p_matrix[iyear,itest] = stats.norm.sf(abs(z_matrix[iyear,itest]))\n",
        "#p_matrix\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "877XzAAbqLr_"
      },
      "source": [
        "'''\n",
        "### Plot the one-sided p-value for each test run, my_var\n",
        "enable_plotly_in_cell()\n",
        "\n",
        "print('This is heatmap of 8 test runs, ',my_var)\n",
        "print('Testing against ',my_ensemble)\n",
        "fig = go.Figure(data=go.Heatmap(\n",
        "                    z=p_matrix,x = test_list))\n",
        "\n",
        "fig.update_layout(\n",
        "    showlegend = True,\n",
        "    width = 700, height = 700,\n",
        "    autosize = False,xaxis_title=\"Test runs \",yaxis_title=\"Years\" )\n",
        "fig.show()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvoNs89pQmHI"
      },
      "source": [
        "fig = plt.figure(1)\n",
        "plt.hist(p_matrix[:,2], density=True, histtype='stepfilled', alpha=0.2)\n",
        "res = stats.kstest(p_matrix[:,2],'uniform')\n",
        "xlim = plt.gca().get_xlim()\n",
        "ylim = plt.gca().get_ylim()\n",
        "plt.text(xlim[1]*0.8,ylim[1]*0.8,'p-value: '+str(round(res[1],2)))\n",
        "res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdSvDW-W0CeH"
      },
      "source": [
        "### 9 subplots\n",
        "normalize_y = False\n",
        "nrow = 3\n",
        "ncol = 3\n",
        "fig = plt.figure(figsize=(12,12))\n",
        "plt.subplots_adjust(wspace = 0.4,hspace= 0.3)\n",
        "\n",
        "#fig = plt.figure(figsize=(8,8))\n",
        "var_list = ['TS','TSMN','TSMX','VT','VU','U10','LWCF','BURDEN2','CCN3']\n",
        "\n",
        "plt.tight_layout()\n",
        "my_perc = np.arange(1,100,1)\n",
        "# Set to True to use only 25 simulations \n",
        "matched = True \n",
        "\n",
        "if not matched:\n",
        "  gnu_df = df[(df.Label == 'GNU')]\n",
        "  intel_df = df[(df.Label == 'Intel') ]\n",
        "  intel_perc = np.nanpercentile(df[(df.Label == 'Intel')][my_var],my_perc)\n",
        "  all_test_df= df[(df.Label == 'Test') ]\n",
        "else:\n",
        "  match_list = [str(simu).zfill(3) for simu in range(25)]\n",
        "  match_list.remove('000')\n",
        "  gnu_df = df[(df.Label == 'GNU') & (df.Simulation.isin(match_list))]\n",
        "  intel_df = df[(df.Label == 'Intel') & (df.Simulation.isin(match_list))]\n",
        "  all_test_df= df[(df.Label == 'Test') ]\n",
        "  intel_df = intel_df.dropna(how = 'any')\n",
        "  gnu_df = gnu_df.dropna(how = 'any')\n",
        "\n",
        "for irow in range(nrow):\n",
        "  for icol in range(ncol):\n",
        "    idx = ncol*irow+icol\n",
        "    ax = plt.subplot(nrow,ncol,idx+1)\n",
        "    my_var = var_list[idx]\n",
        "    \n",
        "    gb1 = intel_df.groupby('nyear')\n",
        "    gb2 = gnu_df.groupby('nyear')\n",
        "\n",
        "    plt.plot(np.arange(0,100),gb1.mean()[my_var],label = 'Intel')\n",
        "    plt.plot(np.arange(0,100),gb2.mean()[my_var],label = 'GNU')\n",
        "    plt.xlabel('Year')\n",
        "    plt.ylabel(my_var)\n",
        "    if irow == 0 and icol == 2:\n",
        "      plt.legend(frameon=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZa2dCeERmRO"
      },
      "source": [
        "#gb.mean()['BURDEN2']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2y0i478Wwzp"
      },
      "source": [
        "#### How to interpret KS statistics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52qBDWjrW1DE"
      },
      "source": [
        "KS Test is a very powerful way to automatically differentiate samples from a different distribution. kstest function may also be used to check whether the data given follows Normal Distribution or not. It compares the observed versus the expected cumulative relative frequencies of the Normal Distribution. The Kolmogorov-Smirnov test uses the maximal absolute difference between the observed and expected cumulative distribution.\n",
        "\n",
        "The Null hypothesis used here assumes that the numbers follow the normal distribution.\n",
        "The functioning of the function remains exactly same. Again it returns statistics and p-value. If the p-value is < alpha, we reject the Null hypothesis.\n",
        "\n",
        "https://www.geeksforgeeks.org/ml-kolmogorov-smirnov-test/\n",
        "\n",
        "\n",
        "https://stackoverflow.com/questions/39132469/how-to-interpret-scipy-stats-kstest-and-ks-2samp-to-evaluate-fit-of-data-t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMtClymmWK7r"
      },
      "source": [
        "res.pvalue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAvs6Wxv8tJT"
      },
      "source": [
        "How to interpret the results above? \n",
        "- Last columns seems much darker (blue/purple), which means p-value is small: More likely to be in from a different distribution. \n",
        "\n",
        "- Intended to see whether there's change in time axis: First year more similar to each other? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brjJfMhGkhWa"
      },
      "source": [
        "### Sanity Check (Quality control of data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNYVfpuSVpki"
      },
      "source": [
        "#### QQ-plot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7F7fQD3VtKA"
      },
      "source": [
        "100yr average. Vs gaussian. Vs GNU, VS test. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCkAncjMSCjG"
      },
      "source": [
        "Aggregated over 100 years: Intel vs GNU. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBUOUPmxhc_Z"
      },
      "source": [
        "def qqplot(df, my_var):\n",
        "    #function from above, but without the color generator\n",
        "    newdf = df.dropna(subset=[my_var]).copy()\n",
        "    fig = plt.figure(2,figsize = (8,8))\n",
        "    my_perc = np.arange(0,100,1)\n",
        "    # Set to True to use only 25 simulations \n",
        "    matched = True \n",
        "    color_list = ['#e41a1c','#377eb8','#4daf4a','#984ea3','#ff7f00','#ffff33','#a65628','#f781bf']#['#a6cee3','#1f78b4','#b2df8a','#33a02c','#fb9a99','#e31a1c','#fdbf6f','#ff7f00']\n",
        "\n",
        "    if not matched:\n",
        "      intel_perc = np.nanpercentile(newdf[(newdf.Label == 'Intel')][my_var],my_perc)\n",
        "    else:\n",
        "      match_list = [str(simu).zfill(3) for simu in range(25)]\n",
        "      #match_list = [(simu) for simu in range(25)]\n",
        "      intel_perc = np.nanpercentile(newdf[(newdf.Label == 'Intel') & (newdf.Simulation.isin(match_list))][my_var],my_perc)\n",
        "    gnu_perc = np.nanpercentile(newdf[newdf.Label == 'GNU'][my_var],my_perc)\n",
        "\n",
        "    ax = plt.subplot()\n",
        "    vmin = np.round(np.nanmin([intel_perc,gnu_perc]),decimals=2)\n",
        "    vmax = np.round(np.nanmax([intel_perc,gnu_perc]),decimals=2)\n",
        "\n",
        "    plt.plot([vmin,vmax],[vmin,vmax],'--k')\n",
        "    plt.plot(intel_perc,gnu_perc,'--b',label = 'GNU')\n",
        "    plt.xlabel('Intel',fontsize = 12)\n",
        "    plt.ylabel('GNU/Test',fontsize = 12)\n",
        "\n",
        "    test_list = np.unique(df[df.Label == 'Test']['Simulation'])\n",
        "    for my_test,my_color in zip(test_list,color_list):\n",
        "      test_perc = np.nanpercentile(newdf[(newdf.Simulation == my_test)][my_var],my_perc)\n",
        "      plt.plot(intel_perc,test_perc,c = my_color,label = my_test,lw = 2)\n",
        "\n",
        "    ax.set_xticks(np.round(np.linspace(vmin, vmax, 5), 2))\n",
        "    ax.set_yticks(np.round(np.linspace(vmin, vmax, 5), 2))\n",
        "\n",
        "\n",
        "    plt.title(my_var)\n",
        "    plt.legend()\n",
        "    fig.patch.set_facecolor('xkcd:white')\n",
        "\n",
        "    return fig\n",
        "#qqplot(df,'TS')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_etqu3-MV1qH"
      },
      "source": [
        "Test QQ plot against Gaussian CDF. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAfrTqXWV1XR"
      },
      "source": [
        "newdf = df.dropna(subset=[my_var]).copy()\n",
        "fig = plt.figure(2,figsize = (8,8))\n",
        "my_perc = np.arange(0,100,1)\n",
        "color_list = ['#e41a1c','#377eb8','#4daf4a','#984ea3','#ff7f00','#ffff33','#a65628','#f781bf']#['#a6cee3','#1f78b4','#b2df8a','#33a02c','#fb9a99','#e31a1c','#fdbf6f','#ff7f00']\n",
        "\n",
        "# Set to True to use only 25 simulations \n",
        "matched = True \n",
        "if not matched:\n",
        "  intel_perc = np.nanpercentile(newdf[(newdf.Label == 'Intel')][my_var],my_perc)\n",
        "else:\n",
        "  match_list = [str(simu).zfill(3) for simu in range(25)]\n",
        "  #match_list = [(simu) for simu in range(25)]\n",
        "  intel_perc = np.nanpercentile(newdf[(newdf.Label == 'Intel') & (newdf.Simulation.isin(match_list))][my_var],my_perc)\n",
        "gnu_perc = np.nanpercentile(newdf[newdf.Label == 'GNU'][my_var],my_perc)\n",
        "\n",
        "ax = plt.subplot()\n",
        "vmin = np.round(np.nanmin([intel_perc,gnu_perc]),decimals=2)\n",
        "vmax = np.round(np.nanmax([intel_perc,gnu_perc]),decimals=2)\n",
        "\n",
        "plt.plot([vmin,vmax],[vmin,vmax],'--k')\n",
        "plt.plot(intel_perc,gnu_perc,'--b',label = 'GNU')\n",
        "plt.xlabel('Intel',fontsize = 12)\n",
        "plt.ylabel('GNU/Test',fontsize = 12)\n",
        "\n",
        "test_list = np.unique(df[df.Label == 'Test']['Simulation'])\n",
        "for my_test,my_color in zip(test_list,color_list):\n",
        "  test_perc = np.nanpercentile(newdf[(newdf.Simulation == my_test)][my_var],my_perc)\n",
        "  plt.plot(intel_perc,test_perc,c = my_color,label = my_test,lw = 2)\n",
        "\n",
        "ax.set_xticks(np.round(np.linspace(vmin, vmax, 5), 2))\n",
        "ax.set_yticks(np.round(np.linspace(vmin, vmax, 5), 2))\n",
        "\n",
        "\n",
        "plt.title(my_var)\n",
        "plt.legend()\n",
        "fig.patch.set_facecolor('xkcd:white')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikiU0_ReaVod"
      },
      "source": [
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "\n",
        "var_list = column_list\n",
        "\n",
        "@interact(my_var=var_list)\n",
        "def make_plot_for(my_var='TS'):\n",
        "    plot = qqplot(df, my_var)\n",
        "    #display(plot)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjL1xecDtQBY"
      },
      "source": [
        "Linear fit of all variables, Intel ensemble last 90 years. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkDreRkItTDa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSJG4-pqNUGT"
      },
      "source": [
        "One problem is that I forced low and high end to match. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtwKsGxzbeDE"
      },
      "source": [
        "\n",
        "from scipy.stats import norm\n",
        "normalize_y = False\n",
        "def gaussian_qqplot(my_var,normalize_y):\n",
        "  fig = plt.figure(2,figsize = (8,8))\n",
        "  my_perc = np.arange(1,100,1)\n",
        "  # Set to True to use only 25 simulations \n",
        "  matched = False \n",
        "\n",
        "  if not matched:\n",
        "    gnu_df = df[(df.Label == 'GNU')]\n",
        "    intel_df = df[(df.Label == 'Intel') ]\n",
        "    intel_perc = np.nanpercentile(df[(df.Label == 'Intel')][my_var],my_perc)\n",
        "  else:\n",
        "    match_list = [str(simu).zfill(3) for simu in range(25)]\n",
        "    #match_list.remove('006')\n",
        "    gnu_df = df[(df.Label == 'GNU') & (df.Simulation.isin(match_list))]\n",
        "    intel_df = df[(df.Label == 'Intel') & (df.Simulation.isin(match_list))]\n",
        "  gnu_mean = gnu_df[my_var].mean()\n",
        "  gnu_std = gnu_df[my_var].std()\n",
        "  gnu_perc = np.nanpercentile(df[df.Label == 'GNU'][my_var],my_perc)\n",
        "  if normalize_y:\n",
        "    gnu_perc = [(my_gnu_perc-gnu_mean)/gnu_std for my_gnu_perc in gnu_perc]\n",
        "  intel_mean = intel_df[my_var].mean()\n",
        "  intel_std = intel_df[my_var].std()\n",
        "  intel_perc = np.nanpercentile(df[(df.Label == 'Intel')][my_var],my_perc)\n",
        "  if normalize_y:\n",
        "    intel_perc = [(my_intel_perc-intel_mean)/intel_std for my_intel_perc in intel_perc]\n",
        "  test_perc = np.nanpercentile(df[(df.Label == 'Test')][my_var],my_perc)\n",
        "\n",
        "  #gnu_hist = np.histogram(np.array(gnu_df[my_var]),bins = np.linspace(gnu_df[my_var].min(),gnu_df[my_var].max(),101))[0]\n",
        "  #gnu_hist = gnu_hist/gnu_hist.sum(axis=0, keepdims=True) \n",
        "  #gnu_perc = np.cumsum(gnu_hist)\n",
        "  #intel_hist = np.histogram(np.array(intel_df[my_var]),bins = np.linspace(intel_df[my_var].min(),intel_df[my_var].max(),101))[0]\n",
        "  #intel_hist = intel_hist/intel_hist.sum(axis=0, keepdims=True) \n",
        "  #intel_perc = np.cumsum(intel_hist)\n",
        "\n",
        "  x = [norm.ppf(my_quant) for my_quant in np.linspace(0.01,0.99,99)]\n",
        "  #gaussian_perc = norm.cdf(x)\n",
        "  gaussian_perc = x.copy()\n",
        "\n",
        "  vmin = np.nanmin([gnu_perc,intel_perc])\n",
        "  vmax = np.nanmax([gnu_perc,intel_perc])\n",
        "  plt.plot([np.nanmin(x),np.nanmax(x)],[vmin,vmax],'k--',alpha = 0.5)#,label = 'Gaussian'\n",
        "\n",
        "  plt.plot(gaussian_perc,gnu_perc,'k',linestyle = 'dashdot',label = 'GNU',zorder = 10)\n",
        "  plt.plot(gaussian_perc,intel_perc,'k-',label = 'Intel',zorder = 10)\n",
        "\n",
        "\n",
        "  plt.xlabel('Standard Normal Quantiles',fontsize = 12)\n",
        "  plt.ylabel('Intel/GNU/Test Quantiles',fontsize = 12)\n",
        "\n",
        "  test_list = np.unique(df[df.Label == 'Test']['Simulation'])\n",
        "  for my_test,my_color in zip(test_list,color_list):\n",
        "    test_df = df[df.Simulation == my_test]\n",
        "    #test_hist = np.histogram(np.array(test_df[my_var]),bins = np.linspace(test_df[my_var].min(),test_df[my_var].max(),101))[0]\n",
        "    #test_hist = test_hist/test_hist.sum(axis=0, keepdims=True) \n",
        "    #test_perc = np.cumsum(test_hist)\n",
        "    test_mean = test_df[my_var].mean()\n",
        "    test_std = test_df[my_var].std()\n",
        "    test_perc = np.nanpercentile(test_df[my_var],my_perc)\n",
        "    \n",
        "    if normalize_y:\n",
        "      test_perc = [(my_test_perc-test_mean)/test_std for my_test_perc in test_perc]  \n",
        "    plt.plot(gaussian_perc,test_perc,label = my_test,color = my_color)\n",
        "\n",
        "  #ax.set_xticks(np.round(np.linspace(np.nanmin(x), np.nanmax(x), 5), 5))\n",
        "  #ax.set_yticks(np.round(np.linspace(vmin, vmax, 5), 5))\n",
        "  vmin = np.nanmin([gnu_perc,intel_perc,test_perc])\n",
        "  vmax = np.nanmax([gnu_perc,intel_perc,test_perc])\n",
        "  ax.set_xticks((np.linspace(np.nanmin(x), np.nanmax(x), 5)))\n",
        "  ax.set_yticks((np.linspace(vmin, vmax, 5)))\n",
        "\n",
        "\n",
        "  plt.title(my_var)\n",
        "  plt.legend()\n",
        "  return ax #fig\n",
        "\n",
        "gaussian_qqplot('BURDEN2',False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URrqZZyhwQs5"
      },
      "source": [
        "\n",
        "from scipy.stats import norm\n",
        "normalize_y = False\n",
        "\n",
        "# QUantile ratio plot\n",
        "def gaussian_qrplot(my_var,normalize_y):\n",
        "  fig = plt.figure(2,figsize = (8,8))\n",
        "  my_perc = np.arange(1,100,1)\n",
        "  # Set to True to use only 25 simulations \n",
        "  matched = False \n",
        "\n",
        "  if not matched:\n",
        "    gnu_df = df[(df.Label == 'GNU')]\n",
        "    intel_df = df[(df.Label == 'Intel') ]\n",
        "    intel_perc = np.nanpercentile(df[(df.Label == 'Intel')][my_var],my_perc)\n",
        "  else:\n",
        "    match_list = [str(simu).zfill(3) for simu in range(25)]\n",
        "    #match_list.remove('006')\n",
        "    gnu_df = df[(df.Label == 'GNU') & (df.Simulation.isin(match_list))]\n",
        "    intel_df = df[(df.Label == 'Intel') & (df.Simulation.isin(match_list))]\n",
        "  gnu_mean = gnu_df[my_var].mean()\n",
        "  gnu_std = gnu_df[my_var].std()\n",
        "  gnu_perc = np.nanpercentile(df[df.Label == 'GNU'][my_var],my_perc)\n",
        "  if normalize_y:\n",
        "    gnu_perc = [(my_gnu_perc-gnu_mean)/gnu_std for my_gnu_perc in gnu_perc]\n",
        "  intel_mean = intel_df[my_var].mean()\n",
        "  intel_std = intel_df[my_var].std()\n",
        "  intel_perc = np.nanpercentile(df[(df.Label == 'Intel')][my_var],my_perc)\n",
        "  if normalize_y:\n",
        "    intel_perc = [(my_intel_perc-intel_mean)/intel_std for my_intel_perc in intel_perc]\n",
        "  test_perc = np.nanpercentile(df[(df.Label == 'Test')][my_var],my_perc)\n",
        "\n",
        "  new_qr = intel_perc/gnu_perc\n",
        "  #gnu_hist = np.histogram(np.array(gnu_df[my_var]),bins = np.linspace(gnu_df[my_var].min(),gnu_df[my_var].max(),101))[0]\n",
        "  #gnu_hist = gnu_hist/gnu_hist.sum(axis=0, keepdims=True) \n",
        "  #gnu_perc = np.cumsum(gnu_hist)\n",
        "  #intel_hist = np.histogram(np.array(intel_df[my_var]),bins = np.linspace(intel_df[my_var].min(),intel_df[my_var].max(),101))[0]\n",
        "  #intel_hist = intel_hist/intel_hist.sum(axis=0, keepdims=True) \n",
        "  #intel_perc = np.cumsum(intel_hist)\n",
        "\n",
        "  x = [norm.ppf(my_quant) for my_quant in np.linspace(0.01,0.99,99)]\n",
        "  #gaussian_perc = norm.cdf(x)\n",
        "  gaussian_perc = x.copy()\n",
        "\n",
        "  vmin = np.nanmin(new_qr)\n",
        "  vmax = np.nanmax(new_qr)\n",
        "  plt.plot([np.nanmin(x),np.nanmax(x)],[vmin,vmax],'k--',alpha = 0.5)#,label = 'Gaussian'\n",
        "\n",
        "  plt.plot(gaussian_perc,new_qr,'k',linestyle = '-',label = 'Quant-ratio',zorder = 10)\n",
        "  #plt.plot(gaussian_perc,intel_perc,'k-',label = 'Intel',zorder = 10)\n",
        "\n",
        "\n",
        "  plt.xlabel('Standard Normal Quantiles',fontsize = 12)\n",
        "  plt.ylabel('Quantile Ratio Intel/GNU',fontsize = 12)\n",
        "\n",
        "  test_list = np.unique(df[df.Label == 'Test']['Simulation'])\n",
        "  for my_test,my_color in zip(test_list,color_list):\n",
        "    test_df = df[df.Simulation == my_test]\n",
        "    #test_hist = np.histogram(np.array(test_df[my_var]),bins = np.linspace(test_df[my_var].min(),test_df[my_var].max(),101))[0]\n",
        "    #test_hist = test_hist/test_hist.sum(axis=0, keepdims=True) \n",
        "    #test_perc = np.cumsum(test_hist)\n",
        "    test_mean = test_df[my_var].mean()\n",
        "    test_std = test_df[my_var].std()\n",
        "    test_perc = np.nanpercentile(test_df[my_var],my_perc)\n",
        "    \n",
        "    if normalize_y:\n",
        "      test_perc = [(my_test_perc-test_mean)/test_std for my_test_perc in test_perc]  \n",
        "    #plt.plot(gaussian_perc,test_perc,label = my_test,color = my_color)\n",
        "\n",
        "  #ax.set_xticks(np.round(np.linspace(np.nanmin(x), np.nanmax(x), 5), 5))\n",
        "  #ax.set_yticks(np.round(np.linspace(vmin, vmax, 5), 5))\n",
        "  vmin = np.nanmin([gnu_perc,intel_perc,test_perc])\n",
        "  vmax = np.nanmax([gnu_perc,intel_perc,test_perc])\n",
        "  ax.set_xticks((np.linspace(np.nanmin(x), np.nanmax(x), 5)))\n",
        "  ax.set_yticks((np.linspace(vmin, vmax, 5)))\n",
        "\n",
        "\n",
        "  plt.title(my_var)\n",
        "  plt.legend()\n",
        "  return ax #fig\n",
        "\n",
        "#gaussian_qrplot('BURDEN2',False)\n",
        "### 9 subplots\n",
        "normalize_y = False\n",
        "nrow = 3\n",
        "ncol = 3\n",
        "fig = plt.figure(figsize=(12,12))\n",
        "plt.subplots_adjust(wspace = 0.3,hspace= 0.3)\n",
        "\n",
        "#fig = plt.figure(figsize=(8,8))\n",
        "var_list = ['TS','TSMN','TSMX','VT','VU','U10','LWCF','BURDEN2','CCN3']\n",
        "\n",
        "plt.tight_layout()\n",
        "my_perc = np.arange(1,100,1)\n",
        "# Set to True to use only 25 simulations \n",
        "matched = False \n",
        "use_year = 100\n",
        "nyear= 100\n",
        "\n",
        "if not matched:\n",
        "  gnu_df = df[(df.Label == 'GNU') & (df.nyear >= nyear - use_year)]\n",
        "  intel_df = df[(df.Label == 'Intel') & (df.nyear >= nyear - use_year)]\n",
        "  intel_perc = np.nanpercentile(intel_df[my_var],my_perc)\n",
        "  all_test_df= df[(df.Label == 'Test') & (df.nyear >= nyear - use_year)]\n",
        "else:\n",
        "  match_list = [str(simu).zfill(3) for simu in range(25)]\n",
        "  match_list.remove('000')\n",
        "  gnu_df = df[(df.Label == 'GNU') & (df.Simulation.isin(match_list)) & (df.nyear >= nyear - use_year)]\n",
        "  intel_df = df[(df.Label == 'Intel') & (df.Simulation.isin(match_list)) & (df.nyear >= nyear - use_year)]\n",
        "  all_test_df= df[(df.Label == 'Test') & (df.nyear >= nyear - use_year)]\n",
        "\n",
        "for irow in range(nrow):\n",
        "  for icol in range(ncol):\n",
        "    idx = ncol*irow+icol\n",
        "    ax = plt.subplot(nrow,ncol,idx+1)\n",
        "    my_var = var_list[idx]\n",
        "\n",
        "      \n",
        "\n",
        "    gnu_mean = gnu_df[my_var].mean()\n",
        "    gnu_std = gnu_df[my_var].std()\n",
        "    #if np.nanmin(gnu_df[my_var])*np.nanmax(gnu_df[my_var]) < 0:\n",
        "    gnu_perc = np.nanpercentile(abs(gnu_df[my_var]),my_perc)\n",
        "    if normalize_y:\n",
        "      gnu_perc = [(my_gnu_perc-gnu_mean)/gnu_std for my_gnu_perc in gnu_perc]\n",
        "    intel_mean = intel_df[my_var].mean()\n",
        "    intel_std = intel_df[my_var].std()\n",
        "    #intel_perc = np.nanpercentile(intel_df[my_var],my_perc)\n",
        "    intel_perc = np.nanpercentile(abs(intel_df[my_var]),my_perc)\n",
        "    if normalize_y:\n",
        "      intel_perc = [(my_intel_perc-intel_mean)/intel_std for my_intel_perc in intel_perc]\n",
        "    test_perc = np.nanpercentile(df[(df.Label == 'Test')][my_var],my_perc)\n",
        "\n",
        "    #gnu_hist = np.histogram(np.array(gnu_df[my_var]),bins = np.linspace(gnu_df[my_var].min(),gnu_df[my_var].max(),101))[0]\n",
        "    #gnu_hist = gnu_hist/gnu_hist.sum(axis=0, keepdims=True) \n",
        "    #gnu_perc = np.cumsum(gnu_hist)\n",
        "    #intel_hist = np.histogram(np.array(intel_df[my_var]),bins = np.linspace(intel_df[my_var].min(),intel_df[my_var].max(),101))[0]\n",
        "    #intel_hist = intel_hist/intel_hist.sum(axis=0, keepdims=True) \n",
        "    #intel_perc = np.cumsum(intel_hist)\n",
        "\n",
        "    x = [norm.ppf(my_quant) for my_quant in np.linspace(0.01,0.99,99)]\n",
        "    #gaussian_perc = norm.cdf(x)\n",
        "    gaussian_perc = x.copy()\n",
        "    new_qr  = intel_perc/gnu_perc\n",
        "    vmin = np.nanmin(new_qr)\n",
        "    vmax = np.nanmax(new_qr)\n",
        "    \n",
        "\n",
        "    #plt.plot([np.nanmin(x),np.nanmax(x)],[vmin,vmax],'k--',alpha = 0.5)#,label = 'Gaussian'\n",
        "    plt.hlines(1,np.nanmin(x),np.nanmax(x),linestyle ='--',alpha = 0.5)#,label = 'Gaussian'\n",
        "\n",
        "    plt.plot(gaussian_perc,new_qr,'k',linestyle = '-',label = 'Quant-Ratio',zorder = 10)\n",
        "    #plt.plot(gaussian_perc,intel_perc,'k-',label = 'Intel',zorder = 10)\n",
        "\n",
        "    if idx == 7:\n",
        "      plt.xlabel('Standard Normal Quantiles',fontsize = 12)\n",
        "    if idx == 3:\n",
        "      plt.ylabel('Quantile Ratio Intel/GNU',fontsize = 12)\n",
        "\n",
        "\n",
        "    test_list = np.unique(df[df.Label == 'Test']['Simulation'])\n",
        "    for my_test,my_color in zip(test_list,color_list):\n",
        "      test_df = df[df.Simulation == my_test]\n",
        "      #test_hist = np.histogram(np.array(test_df[my_var]),bins = np.linspace(test_df[my_var].min(),test_df[my_var].max(),101))[0]\n",
        "      #test_hist = test_hist/test_hist.sum(axis=0, keepdims=True) \n",
        "      #test_perc = np.cumsum(test_hist)\n",
        "      test_mean = test_df[my_var].mean()\n",
        "      test_std = test_df[my_var].std()\n",
        "      test_perc = np.nanpercentile(test_df[my_var],my_perc)\n",
        "      if normalize_y:\n",
        "        test_perc = [(my_test_perc-test_mean)/test_std for my_test_perc in test_perc]  \n",
        "      #plt.plot(gaussian_perc,test_perc,label = my_test,color = my_color)\n",
        "\n",
        "\n",
        "    #vmin = np.nanmin([gnu_perc,intel_perc,test_perc])\n",
        "    #vmax = np.nanmax([gnu_perc,intel_perc,test_perc])\n",
        "    #vmin = np.nanmin([gnu_perc,intel_perc])\n",
        "    #vmax = np.nanmax([gnu_perc,intel_perc])\n",
        "    ax.set_xticks((np.linspace(np.nanmin(x), np.nanmax(x), 5)))\n",
        "    ax.set_yticks((np.linspace(vmin, vmax, 5)))\n",
        "\n",
        "\n",
        "    plt.title(my_var)\n",
        "    if idx == 2:\n",
        "      plt.legend(frameon=False,bbox_to_anchor=(1.1, 0.5, 0.5, 0.5))\n",
        "    \n",
        "\n",
        "#plt.savefig(local_dir+'qq_plot_nine_variables_latter_'+str(use_year)+'.png',dpi = 500)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRGFm-yQ2bAE"
      },
      "source": [
        "### 9 subplots\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "normalize_y = False\n",
        "nrow = 3\n",
        "ncol = 3\n",
        "fig = plt.figure(figsize=(12,12))\n",
        "plt.subplots_adjust(wspace = 0.3,hspace= 0.3)\n",
        "\n",
        "#fig = plt.figure(figsize=(8,8))\n",
        "var_list = ['TS','TSMN','TSMX','VT','VU','U10','LWCF','BURDEN2','CCN3']\n",
        "\n",
        "plt.tight_layout()\n",
        "my_perc = np.arange(1,100,1)\n",
        "# Set to True to use only 25 simulations \n",
        "matched = False \n",
        "use_year = 90\n",
        "nyear= 100\n",
        "\n",
        "if not matched:\n",
        "  gnu_df = df[(df.Label == 'GNU') & (df.nyear >= nyear - use_year)]\n",
        "  intel_df = df[(df.Label == 'Intel') & (df.nyear >= nyear - use_year)]\n",
        "  intel_perc = np.nanpercentile(intel_df[my_var],my_perc)\n",
        "  all_test_df= df[(df.Label == 'Test') & (df.nyear >= nyear - use_year)]\n",
        "else:\n",
        "  match_list = [str(simu).zfill(3) for simu in range(25)]\n",
        "  match_list.remove('000')\n",
        "  gnu_df = df[(df.Label == 'GNU') & (df.Simulation.isin(match_list)) & (df.nyear >= nyear - use_year)]\n",
        "  intel_df = df[(df.Label == 'Intel') & (df.Simulation.isin(match_list)) & (df.nyear >= nyear - use_year)]\n",
        "  all_test_df= df[(df.Label == 'Test') & (df.nyear >= nyear - use_year)]\n",
        "\n",
        "for irow in range(nrow):\n",
        "  for icol in range(ncol):\n",
        "    idx = ncol*irow+icol\n",
        "    ax = plt.subplot(nrow,ncol,idx+1)\n",
        "    my_var = var_list[idx]\n",
        "\n",
        "      \n",
        "\n",
        "    gnu_mean = gnu_df[my_var].mean()\n",
        "    gnu_std = gnu_df[my_var].std()\n",
        "    gnu_perc = np.nanpercentile(gnu_df[my_var],my_perc)\n",
        "    if normalize_y:\n",
        "      gnu_perc = [(my_gnu_perc-gnu_mean)/gnu_std for my_gnu_perc in gnu_perc]\n",
        "    intel_mean = intel_df[my_var].mean()\n",
        "    intel_std = intel_df[my_var].std()\n",
        "    intel_perc = np.nanpercentile(intel_df[my_var],my_perc)\n",
        "    if normalize_y:\n",
        "      intel_perc = [(my_intel_perc-intel_mean)/intel_std for my_intel_perc in intel_perc]\n",
        "    test_perc = np.nanpercentile(df[(df.Label == 'Test')][my_var],my_perc)\n",
        "\n",
        "    #gnu_hist = np.histogram(np.array(gnu_df[my_var]),bins = np.linspace(gnu_df[my_var].min(),gnu_df[my_var].max(),101))[0]\n",
        "    #gnu_hist = gnu_hist/gnu_hist.sum(axis=0, keepdims=True) \n",
        "    #gnu_perc = np.cumsum(gnu_hist)\n",
        "    #intel_hist = np.histogram(np.array(intel_df[my_var]),bins = np.linspace(intel_df[my_var].min(),intel_df[my_var].max(),101))[0]\n",
        "    #intel_hist = intel_hist/intel_hist.sum(axis=0, keepdims=True) \n",
        "    #intel_perc = np.cumsum(intel_hist)\n",
        "\n",
        "    x = [norm.ppf(my_quant) for my_quant in np.linspace(0.01,0.99,99)]\n",
        "    #gaussian_perc = norm.cdf(x)\n",
        "    gaussian_perc = x.copy()\n",
        "    slope, intercept, r_value, p_value, std_err = stats.linregress(x,intel_perc)\n",
        "    print('Linear fit of Intel '+str(my_var)+' r-value =', r_value)\n",
        "    #print('Linear fit of Intel '+str(my_var)+' p-value =', p_value)\n",
        "\n",
        "    vmin = np.nanmin([gnu_perc,intel_perc])\n",
        "    vmax = np.nanmax([gnu_perc,intel_perc])\n",
        "    \n",
        "\n",
        "    plt.plot([np.nanmin(x),np.nanmax(x)],[vmin,vmax],'k--',alpha = 0.5)#,label = 'Gaussian'\n",
        "\n",
        "    plt.plot(gaussian_perc,gnu_perc,'k',linestyle = 'dashdot',label = 'GNU',zorder = 10)\n",
        "    plt.plot(gaussian_perc,intel_perc,'k-',label = 'Intel',zorder = 10)\n",
        "\n",
        "    if idx == 7:\n",
        "      plt.xlabel('Standard Normal Quantiles',fontsize = 12)\n",
        "    if idx == 3:\n",
        "      plt.ylabel('Intel/GNU/Test Quantiles',fontsize = 12)\n",
        "\n",
        "\n",
        "    test_list = np.unique(df[df.Label == 'Test']['Simulation'])\n",
        "    for my_test,my_color in zip(test_list,color_list):\n",
        "      test_df = df[df.Simulation == my_test]\n",
        "      #test_hist = np.histogram(np.array(test_df[my_var]),bins = np.linspace(test_df[my_var].min(),test_df[my_var].max(),101))[0]\n",
        "      #test_hist = test_hist/test_hist.sum(axis=0, keepdims=True) \n",
        "      #test_perc = np.cumsum(test_hist)\n",
        "      test_mean = test_df[my_var].mean()\n",
        "      test_std = test_df[my_var].std()\n",
        "      test_perc = np.nanpercentile(test_df[my_var],my_perc)\n",
        "      if normalize_y:\n",
        "        test_perc = [(my_test_perc-test_mean)/test_std for my_test_perc in test_perc]  \n",
        "      #plt.plot(gaussian_perc,test_perc,label = my_test,color = my_color)\n",
        "\n",
        "\n",
        "    #vmin = np.nanmin([gnu_perc,intel_perc,test_perc])\n",
        "    #vmax = np.nanmax([gnu_perc,intel_perc,test_perc])\n",
        "    vmin = np.nanmin([gnu_perc,intel_perc])\n",
        "    vmax = np.nanmax([gnu_perc,intel_perc])\n",
        "    ax.set_xticks((np.linspace(np.nanmin(x), np.nanmax(x), 5)))\n",
        "    ax.set_yticks((np.linspace(vmin, vmax, 5)))\n",
        "\n",
        "\n",
        "    plt.title(my_var)\n",
        "    if idx == 2:\n",
        "      plt.legend(frameon=False)#bbox_to_anchor=(1.1, 0.5, 0.5, 0.5)\n",
        "    if idx == 7:\n",
        "      ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2e'))\n",
        "    else:\n",
        "      ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2f'))\n",
        "\n",
        "\n",
        "plt.savefig(local_dir+'qq_plot_nine_variables_latter_'+str(use_year)+'.png',dpi = 500)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DZ8F7xnu3yX"
      },
      "source": [
        "\n",
        "for my_var in removed_column_list:\n",
        "  r_value_list = []\n",
        "  for my_test in test_list:\n",
        "\n",
        "    gnu_mean = gnu_df[my_var].mean()\n",
        "    gnu_std = gnu_df[my_var].std()\n",
        "    gnu_perc = np.nanpercentile(gnu_df[my_var],my_perc)\n",
        "    if normalize_y:\n",
        "      gnu_perc = [(my_gnu_perc-gnu_mean)/gnu_std for my_gnu_perc in gnu_perc]\n",
        "    intel_mean = intel_df[my_var].mean()\n",
        "    intel_std = intel_df[my_var].std()\n",
        "    intel_perc = np.nanpercentile(intel_df[my_var],my_perc)\n",
        "    if normalize_y:\n",
        "      intel_perc = [(my_intel_perc-intel_mean)/intel_std for my_intel_perc in intel_perc]\n",
        "    test_perc = np.nanpercentile(df[(df.Label == 'Test') & (df.Simulation == my_test)][my_var],my_perc)\n",
        "\n",
        "\n",
        "    x = [norm.ppf(my_quant) for my_quant in np.linspace(0.01,0.99,99)]\n",
        "    #gaussian_perc = norm.cdf(x)\n",
        "    gaussian_perc = x.copy()\n",
        "    slope, intercept, r_value, p_value, std_err = stats.linregress(x,test_perc)\n",
        "    if r_value < 0.98:\n",
        "      print('Linear fit of '+str(my_test)+' '+str(my_var)+' r-value =', r_value)\n",
        "    if slope > 1.1:\n",
        "      print('Linear fit of '+str(my_test)+' '+str(my_var)+' slope =', slope)\n",
        "\n",
        "    r_value_list.append(r_value)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lTnMe-HvQYJ"
      },
      "source": [
        "np.nanmin(r_value_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvW8QFu-mOBF"
      },
      "source": [
        "This is the quantile ratio plot against standard Gaussian. If the points align on a straight line, then it is Gaussian. The steeper the slope is, the wider. the distribution. \n",
        "If it is flat in lower x, it means it misses the low extreme. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoI1TRsuS7vw"
      },
      "source": [
        "var_list = column_list\n",
        "\n",
        "@interact(my_var=var_list)\n",
        "def make_plot_for(my_var='TS'):\n",
        "    plot = gaussian_qqplot(my_var,normalize_y = False)\n",
        "    #display(plot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yw3fQJjZNuPo"
      },
      "source": [
        "#df[(df.Label == 'Intel') & (df.Simulation == '115') & (df.nyear > 94)].describe()\n",
        "fs = 14"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLB7yJUPkqX9"
      },
      "source": [
        "#### Show all standard deviation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ApiNzh-kvDd"
      },
      "source": [
        "There should not be a standard deviation exceeding E+30"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhZt-8tgk0ug"
      },
      "source": [
        "#df[(df.Label == 'Intel') & (df.Simulation == '034')]['TS'].plot()\n",
        "'''\n",
        "for col in column_list:\n",
        "  for my_simu in ['Intel','GNU','Test']:\n",
        "    #if my_simu == 'Intel':\n",
        "    #  my_std = df[(df.Label == 'Intel') & (df.Simulation != '006')][[col]].std()\n",
        "    #else:\n",
        "    #  my_std = df[(df.Label == my_simu)][[col]].std()\n",
        "    my_std = df[(df.Label == my_simu)][[col]].std()\n",
        "    if my_std[col] > 100:\n",
        "      print(my_simu,col,my_std[col])\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS4FVft-mRDr"
      },
      "source": [
        "The first years could be different"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5ZicedVlQHq"
      },
      "source": [
        "'''\n",
        "divide_year = 9\n",
        "my_var = 'TS'\n",
        "intel_mean = intel_df[intel_df.nyear > divide_year][my_var].mean()\n",
        "gnu_mean = gnu_df[gnu_df.nyear > divide_year][my_var].mean()\n",
        "my_cov = np.zeros(divide_year)\n",
        "for first_years in range(divide_year):\n",
        "  for simu in match_list:\n",
        "    xi = intel_df[(intel_df.Simulation == simu) & (intel_df.nyear == first_years)][my_var].mean()\n",
        "    yi = gnu_df[(gnu_df.Simulation == simu) & (gnu_df.nyear == first_years)][my_var].mean()\n",
        "    my_cov[first_years] = my_cov[first_years] + (xi - intel_mean)*(yi - gnu_mean)\n",
        "my_cov\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "appn9O4O9lKZ"
      },
      "source": [
        "#sns.lineplot(range(divide_year),my_cov)\n",
        "#plt.hlines(0,0,divide_year,linestyles='--')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UH4arggCFHNY"
      },
      "source": [
        "#### Testing normality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50dVlcn3FKYi"
      },
      "source": [
        "Here we use KS-test or Shapiro-Wilk test to test normality of each variable, all years & simulations aggregated. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7jsM8NMFJkg"
      },
      "source": [
        "\n",
        "my_ens = df[df.Simulation == test_list[5]]#intel_df[intel_df.Simulation != '000']\n",
        "ci =0.05\n",
        "#my_ens = intel_df\n",
        "shap_pval = np.zeros(len(column_list))\n",
        "ks_pval = np.zeros(len(column_list))\n",
        "shap_pval.fill(np.nan)\n",
        "ks_pval.fill(np.nan)\n",
        "for idx,my_var in enumerate(column_list):\n",
        "  if my_ens[my_var].std() > 0:\n",
        "    shap_pval[idx] = stats.shapiro((my_ens[my_var] - my_ens[my_var].mean())/(my_ens[my_var].std()))[1]\n",
        "    ks_pval[idx] = stats.kstest((my_ens[my_var] - my_ens[my_var].mean())/(my_ens[my_var].std()),'norm')[1]\n",
        "    #ks_pval[idx] = stats.kstest((my_ens[my_var] - my_ens[my_var].mean()),'norm')[1]\n",
        "  if ks_pval[idx] < ci:\n",
        "    print(my_var)\n",
        "'''\n",
        "var_list = ['TS','TSMN','TSMX','VT','VU','U10','LWCF','BURDEN2','CCN3']\n",
        "my_ens = intel_df[intel_df.Simulation != '000']\n",
        "shap_pval = np.zeros(len(var_list))\n",
        "ks_pval = np.zeros(len(var_list))\n",
        "shap_pval.fill(np.nan)\n",
        "ks_pval.fill(np.nan)\n",
        "my_mean =  np.zeros(len(var_list))\n",
        "my_variance =  np.zeros(len(var_list))\n",
        "for idx,my_var in enumerate(var_list):\n",
        "  if my_ens[my_var].std() > 0:\n",
        "    shap_pval[idx] = stats.shapiro((my_ens[my_var] - my_ens[my_var].mean())/(my_ens[my_var].std()))[1]\n",
        "    ks_pval[idx] = stats.kstest((my_ens[my_var] - my_ens[my_var].mean())*1./(my_ens[my_var].std()),'norm')[1]\n",
        "    my_mean[idx] = my_ens[my_var].mean()\n",
        "    my_variance[idx] = my_ens[my_var].var()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ix5_GnfdX6tp"
      },
      "source": [
        "column_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy8DMcYjW55U"
      },
      "source": [
        "fs = 14"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3ZmThwLk25P"
      },
      "source": [
        "mean_stats = pd.DataFrame()\n",
        "mean_stats['Variable'] = var_list\n",
        "#mean_stats['Mean'] = my_mean\n",
        "#mean_stats['Variance'] = my_variance\n",
        "\n",
        "mean_stats['KS-pvalue'] = [round(ks_p,2) for ks_p in ks_pval]\n",
        "#my_ens['BURDEN2'].hist()\n",
        "mean_stats.transpose()\n",
        "\n",
        "\n",
        "#df[df['TSMX'] < 290]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1acCj2s1F1Zp"
      },
      "source": [
        "plt.plot(np.sort(shap_pval),label='Shapiro-Wilk test')\n",
        "plt.plot(np.sort(ks_pval),label = 'KS test')\n",
        "plt.legend()\n",
        "\n",
        "len(ks_pval[ks_pval < 0.05])/len(ks_pval)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PA0TaxYwkbXK"
      },
      "source": [
        "### Testing hypothesis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3zziwEuN-dL"
      },
      "source": [
        "def KL(P,Q):\n",
        "     epsilon = 0.00001\n",
        "\n",
        "     # You may want to instead make copies to avoid changing the np arrays.\n",
        "     P = P+epsilon\n",
        "     Q = Q+epsilon\n",
        "\n",
        "     divergence = np.sum(P*np.log(P/Q))\n",
        "     return divergence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdmRyN0fVaS7"
      },
      "source": [
        "#### KS-test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSCB2F2xWil8"
      },
      "source": [
        "Test the null hypothesis Ho:\n",
        "The randomly picked GNU run is different from the Intel ensemble distribution across 100 years (assuming stationarity). \n",
        "\n",
        "If the K-S statistic is small or the p-value is high, then we cannot reject the hypothesis that the distributions of the two samples are the same.\n",
        "https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.ks_2samp.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ypg4T1xVZ2l"
      },
      "source": [
        "'''\n",
        "### Testing a random GNU run\n",
        "use_year = False\n",
        "my_var = 'TS'\n",
        "matched = True \n",
        "\n",
        "\n",
        "if use_year:\n",
        "  match_list = [str(simu).zfill(3) for simu in np.random.randint(0,25,1)]\n",
        "  intel_df = df[(df.Label == 'Intel') & (df.Simulation.isin(match_list))]\n",
        "  gnu_df = df[(df.Label == 'GNU') & (df.Simulation.isin(match_list))]\n",
        "else:\n",
        "  if not matched:\n",
        "    gnu_df = df[(df.Label == 'GNU')]\n",
        "    intel_df = df[(df.Label == 'Intel') ]\n",
        "  else:\n",
        "    match_list = [str(simu).zfill(3) for simu in range(25)]\n",
        "    #match_list.remove('006')\n",
        "    gnu_df = df[(df.Label == 'GNU') & (df.Simulation.isin(match_list))]\n",
        "    intel_df = df[(df.Label == 'Intel') & (df.Simulation.isin(match_list))]\n",
        "\n",
        "res = stats.ks_2samp(np.array(gnu_df[my_var]),np.array(intel_df[my_var]))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1lX0xvEwmaD"
      },
      "source": [
        "# All matched ensembles\n",
        "use_year = 100\n",
        "matched = False\n",
        "match_list = [str(simu).zfill(3) for simu in range(25)]\n",
        "match_list.remove('000')\n",
        "### If use 25 runs\n",
        "\n",
        "\n",
        "if matched:\n",
        "  intel_df = df[(df.Label == 'Intel') & (df.Simulation.isin(match_list)) & (df.nyear >= nyear - use_year)]\n",
        "  gnu_df = df[(df.Label == 'GNU') & (df.Simulation.isin(match_list)) & (df.nyear >= nyear - use_year)]\n",
        "else:\n",
        "  intel_df = df[(df.Label == 'Intel') & (df.nyear >= nyear - use_year)]\n",
        "  gnu_df = df[(df.Label == 'GNU') & (df.nyear >= nyear - use_year)]\n",
        "  print('Latter '+str(use_year)+' years are used.')\n",
        "\n",
        "\n",
        "var_list = column_list #['TS','TSMN','TSMX']#\n",
        "ci = 0.05 # confidence interval\n",
        "ks_pvalue = np.zeros(len(var_list))\n",
        "ks_stats = np.zeros(len(var_list))\n",
        "for icol,my_var in enumerate(var_list):\n",
        "  res = stats.ks_2samp(np.array(gnu_df[my_var]),np.array(intel_df[my_var]))\n",
        "  ks_stats[icol]= res[0]\n",
        "  ks_pvalue[icol]= res[1]\n",
        "  if res[1] < ci:\n",
        "    print('This is variable: ',my_var)\n",
        "\n",
        "fig = plt.figure(figsize = (12,5))\n",
        "'''\n",
        "plt.scatter(ks_stats,ks_pvalue)\n",
        "xlim = plt.gca().get_xlim()\n",
        "plt.hlines(ci,xlim[0],xlim[1],linestyle = '--')\n",
        "print('Percent of variables rejected null hypothesis at CI=',str(int(ci*100)),'% is ',str(len(ks_pvalue[np.where(ks_pvalue < ci)])*1./len(ks_pvalue)))\n",
        "'''\n",
        "ax = plt.subplot(1,2,1)\n",
        "plt.hist(ks_pvalue,bins = np.arange(0,1,0.05),histtype='stepfilled',alpha = 0.6, linewidth=2)\n",
        "plt.ylabel('Histogram',fontsize =fs)\n",
        "plt.xlim(-0.05,1.05)\n",
        "plt.vlines(0.05,0,13,linestyle = '--')\n",
        "plt.annotate('95% CI',xy = (0.05,10),xytext=(0.1,11),arrowprops=dict(arrowstyle=\"->\",\n",
        "                            connectionstyle=\"arc3\"))\n",
        "plt.text(1.0,-1.5,'KS test p-values',fontsize = fs)\n",
        "ax = plt.subplot(1,2,2)\n",
        "plt.hist(ks_pvalue,bins = np.arange(0,1,0.05),density=True, cumulative = True,label='CDF', \n",
        "         histtype='step', alpha=0.55, color='k',linewidth= 2)\n",
        "plt.ylabel ('CDF',fontsize =fs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52kDitZXXuPN"
      },
      "source": [
        "fig = plt.figure(3,figsize = (8,6))\n",
        "bins = np.linspace(np.nanmin([intel_df[my_var].min(),gnu_df[my_var].min()]),np.nanmax([intel_df[my_var].max(),gnu_df[my_var].max()]),40)\n",
        "plt.hist(intel_df[my_var], bins=bins, density=True, histtype='step', cumulative=True,\n",
        "        label='Intel',lw=2)\n",
        "plt.hist(gnu_df[my_var], bins=bins, density=True, histtype='step', cumulative=True,\n",
        "        label='GNU',lw=2)\n",
        "plt.legend(loc = 2,frameon=False)\n",
        "print('KS-statistics: ',res)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HriETes3l4dN"
      },
      "source": [
        "fig = plt.figure(3,figsize = (8,6))\n",
        "test_df = df[df.Simulation == 'rh-min-low']\n",
        "my_var = 'TS'\n",
        "\n",
        "bins = np.linspace(np.nanmin([intel_df[my_var].min(),test_df[my_var].min()]),np.nanmax([intel_df[my_var].max(),test_df[my_var].max()]),40)\n",
        "hist1= plt.hist(intel_df[my_var], bins=bins, density=True, histtype='step', cumulative=True, label='Intel',lw=2)\n",
        "hist2 =plt.hist(test_df[my_var], bins=bins, density=True, histtype='step', cumulative=True, label='rh-min-low',lw=2)\n",
        "plt.legend(loc = 2,frameon=False)\n",
        "plt.ylabel('CDF',fontsize =fs)\n",
        "plt.xlabel('TS (K)',fontsize =fs)\n",
        "print('KS-statistics: ',res)\n",
        "dcdf = abs(hist1[0] - hist2[0])\n",
        "mask = np.where(dcdf == np.nanmax(dcdf))[0]\n",
        "plt.vlines(bins[mask]+0.5*(bins[1]-bins[0]),hist1[0][mask],hist2[0][mask])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwMdmjblpNSM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q61FtaXGCUp"
      },
      "source": [
        "# For each of 25 paired runs\n",
        "\n",
        "var_list = column_list #['TS','TSMN','TSMX']#\n",
        "ci = 0.05 # confidence interval\n",
        "ks_pvalue = np.zeros((len(var_list),len(match_list)))\n",
        "ks_stats = np.zeros((len(var_list),len(match_list)))\n",
        "for icol,my_var in enumerate(var_list):\n",
        "\n",
        "  for isimu,my_simu in enumerate(match_list):\n",
        "    res = stats.ks_2samp(np.array(gnu_df[gnu_df.Simulation == my_simu][my_var]),np.array(intel_df[intel_df.Simulation == my_simu][my_var]))\n",
        "    ks_stats[icol,isimu]= res[0]\n",
        "    ks_pvalue[icol,isimu]= res[1]\n",
        "    if res[1] < ci:\n",
        "       print('This is variable: ',my_var,' ',my_simu)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EAr2S8lUKs0"
      },
      "source": [
        "# For each of test runs against Intel ensemble\n",
        "\n",
        "var_list = column_list #['TS','TSMN','TSMX']#\n",
        "ci = 0.05 # confidence interval\n",
        "num_rej = np.zeros((len(var_list),len(test_list)))\n",
        "intel_df = df[(df.Label == 'Intel') & (df.nyear >= nyear - use_year)]\n",
        "for icol,my_var in enumerate(var_list):\n",
        "  for itest,my_test in enumerate(test_list):\n",
        "    test_df = df[(df.Simulation == my_test) & (df.nyear >= nyear - use_year)]\n",
        "    res = stats.ks_2samp(np.array(test_df[my_var]),np.array(intel_df[my_var]))\n",
        "    if res[1] < ci:\n",
        "      print('This is variable: ',my_var,' ',my_test)\n",
        "      num_rej[icol,itest]+=1 \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiHmdyH5a0-k"
      },
      "source": [
        "tot_rej_var = np.sum(num_rej[:,:],axis=1)\n",
        "for idx, my_var in enumerate(removed_column_list):\n",
        "  if tot_rej_var[idx] == 5:\n",
        "    print(my_var,tot_rej_var[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhcF4Rrmbz5p"
      },
      "source": [
        "len(removed_column_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yrW2SVfIB_k"
      },
      "source": [
        "### For each variable, how many simulations are rejected\n",
        "fig = plt.figure(figsize = (8,8))\n",
        "plt.hist(np.sum(ks_pvalue[:] < ci,axis=0))\n",
        "xlim = plt.gca().get_xlim()\n",
        "plt.hlines(ci,xlim[0],xlim[1],linestyle = '--')\n",
        "print('Percent of variables rejected null hypothesis at CI=',str(int(ci*100)),'% is ',str(len(ks_pvalue[np.where(ks_pvalue < ci)])*1./len(ks_pvalue)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdEQdK3JIIi5"
      },
      "source": [
        "### For each simulation, what percentage of variables are rejected\n",
        "'''\n",
        "fig = plt.figure(figsize = (12,5))\n",
        "ax = plt.subplot(1,2,1)\n",
        "bins = np.arange(-0.5,17.5,1)\n",
        "nbins = len(bins)\n",
        "plt.hist(np.sum(ks_pvalue[:] < ci,axis=1),bins = bins)\n",
        "xlim = plt.gca().get_xlim()\n",
        "plt.ylabel('Histogram',fontsize = fs)\n",
        "plt.text(12,-7,'# of simulations rejected at 95% CI',fontsize = fs)\n",
        "plt.xticks(labels=[str(int(x_tick+0.5)) for x_tick in bins[0::4]],ticks= (np.arange(nbins+1) )[0::4])\n",
        "\n",
        "#plt.hlines(ci,0,16,linestyle = '--')\n",
        "print('Percent of variables rejected null hypothesis at CI=',str(int(ci*100)),'% is ',str(len(ks_pvalue[np.where(ks_pvalue < ci)])*1./len(ks_pvalue)))\n",
        "plt.annotate(column_list[np.sum(ks_pvalue[:] < ci,axis=1) > 10.][0],xy =(15,1), xytext=(12,4),arrowprops=dict(arrowstyle=\"->\",\n",
        "                            connectionstyle=\"arc3\"))\n",
        "\n",
        "ax = plt.subplot(1,2,2)\n",
        "plt.hist(np.sum(ks_pvalue[:] < ci,axis=1), bins= np.arange(-0.5,17.5,1), density=True, cumulative=True, label='CDF DATA', \n",
        "         histtype='step', alpha=0.55, color='k',linewidth= 2)\n",
        "plt.ylabel('CDF',fontsize=fs)\n",
        "plt.xticks(labels=[str(int(x_tick+0.5)) for x_tick in bins[0::4]],ticks= (np.arange(nbins+1) )[0::4])\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F89FKAjtYDYq"
      },
      "source": [
        "bins"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfWh3XraJHSo"
      },
      "source": [
        "det = np.sum(ks_pvalue[:] < 0.05,axis=1)\n",
        "for idet,my_det in enumerate(det):\n",
        "  if my_det > 2:\n",
        "    print(my_det,column_list[idet])\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w1W_4HYFTgU"
      },
      "source": [
        "my_df = gnu_df.copy()\n",
        "divide_year = 5+nyear - use_year\n",
        "test_df = my_df[(my_df.nyear <= divide_year)]\n",
        "ens_df = my_df[(my_df.nyear > divide_year)]\n",
        "\n",
        "\n",
        "x = np.array(ens_df[my_var])\n",
        "y = np.array(test_df[my_var])\n",
        "bins = np.linspace(np.nanmin(np.hstack((x,y))),np.nanmax(np.hstack((x,y))),40)\n",
        " \n",
        "p = plt.hist(x,bins=bins)[0]\n",
        "q = plt.hist(y,bins=bins)[0]\n",
        "p = p/p.sum(axis=0, keepdims=True) \n",
        "q = q/q.sum(axis=0, keepdims=True) \n",
        "#z = np.array(test_df[my_var])\n",
        "\n",
        "\n",
        "\n",
        "# Note slight difference in the final result compared to Dawny33\n",
        "print('This is GNU.000')\n",
        "res = stats.ks_2samp(x,y)\n",
        "print('KS-statistics: ',res)\n",
        "#kl_res = scipy.special.kl_div(x,y)\n",
        "kl_res = KL(p,q)\n",
        "Sp = stats.entropy(np.array(p))\n",
        "Sq = stats.entropy(np.array(q))\n",
        "print('KL-entropy of A: ',Sp)\n",
        "print('KL-entropy of B: ',Sq)\n",
        "print('KL-divergence: ',kl_res)\n",
        "\n",
        "sns.distplot(x,bins=bins)\n",
        "sns.distplot(y,bins=bins)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9GK6kt82tzs"
      },
      "source": [
        "'''\n",
        "import plotly.graph_objects as go\n",
        "import plotly.figure_factory as ff\n",
        "\n",
        "enable_plotly_in_cell()\n",
        "\n",
        "# Load data\n",
        "df = intel_df.copy()\n",
        "#df.columns = [col.replace(\"AAPL.\", \"\") for col in df.columns]\n",
        "\n",
        "# Create figure\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(\n",
        "    ff.create_distplot(df.TS, 'Intel'))\n",
        "\n",
        "# Set title\n",
        "fig.update_layout(\n",
        "    title_text=\"Time series with range slider and selectors\"\n",
        ")\n",
        "\n",
        "# Add range slider\n",
        "fig.update_layout(\n",
        "    xaxis=dict(\n",
        "        rangeslider=dict(\n",
        "            visible=True\n",
        "        ),\n",
        "        type=\"date\"\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qriZIbSYDwKW"
      },
      "source": [
        "### Test all test runs\n",
        "summary_stat = pd.DataFrame()\n",
        "one_line = {\n",
        "    'Dist_A':'',\n",
        "    'Dist_B':'',\n",
        "    'KS-stats':0,\n",
        "    'KS-pvalue':0,\n",
        "    'KL-div':0,\n",
        "    'KL-entropy':0\n",
        "}\n",
        "test_list\n",
        "use_year = 90\n",
        "my_var = 'TS'\n",
        "run_list = np.unique(intel_df.Simulation)\n",
        "\n",
        "for my_test in test_list:\n",
        "  new_line = one_line.copy()\n",
        "  test_df = df[(df.Simulation == my_test) & (df.nyear >= nyear - use_year)]\n",
        "  x = np.array(intel_df[my_var])\n",
        "  y = np.array(test_df[my_var])\n",
        "  bins = np.linspace(np.nanmin(np.hstack((x,y))),np.nanmax(np.hstack((x,y))),40)\n",
        "\n",
        "\n",
        "\n",
        "  p = plt.hist(x,bins=bins)[0]\n",
        "  q = plt.hist(y,bins=bins)[0]\n",
        "  p = p/p.sum(axis=0, keepdims=True) \n",
        "  q = q/q.sum(axis=0, keepdims=True) \n",
        "\n",
        "  print('This is test run: ',my_test)\n",
        "  res = stats.ks_2samp(x,y)\n",
        "  print('KS-statistics: ',res)\n",
        "  Sp = stats.entropy(np.array(x))\n",
        "  print('KL-entropy of A: ',Sp)\n",
        "  #kl_res = scipy.special.kl_div(p,q)\n",
        "  kl_res = KL(p,q)\n",
        "  print('KL-divergence: ',kl_res)\n",
        "  new_line['Dist_A'] = my_test\n",
        "  new_line['Dist_B'] = str(len(run_list))+' Intel'\n",
        "  new_line['KS-stats'] = round(res[0],2)\n",
        "  new_line['KS-pvalue'] = round(res[1],2)\n",
        "  new_line['KL-entropy'] = round(Sp,2)\n",
        "  new_line['KL-div'] = round(kl_res,2)\n",
        "\n",
        "  summary_stat = summary_stat.append(new_line,ignore_index = True)\n",
        "\n",
        "### Add GNU 000 for referencfe\n",
        "test_df = df[(df.Label == 'Intel') & (df.Simulation == '001')]\n",
        "\n",
        "x = np.array(gnu_df[my_var])\n",
        "y = np.array(test_df[my_var])\n",
        "bins = np.linspace(np.nanmin(np.hstack((x,y))),np.nanmax(np.hstack((x,y))),40)\n",
        " \n",
        "p = plt.hist(x,bins=bins)[0]\n",
        "q = plt.hist(y,bins=bins)[0]\n",
        "p = p/p.sum(axis=0, keepdims=True) \n",
        "q = q/q.sum(axis=0, keepdims=True) \n",
        "#z = np.array(test_df[my_var])\n",
        "\n",
        "\n",
        "\n",
        "# Note slight difference in the final result compared to Dawny33\n",
        "print(KL(p, q)) # 0.775278939433\n",
        "print('This is GNU.000')\n",
        "res = stats.ks_2samp(x,y)\n",
        "print('KS-statistics: ',res)\n",
        "#kl_res = scipy.special.kl_div(x,y)\n",
        "kl_res = KL(p,q)\n",
        "Sp = stats.entropy(np.array(x))\n",
        "print('KL-entropy of A: ',Sp)\n",
        "print('KL-divergence: ',kl_res)\n",
        "\n",
        "new_line = one_line.copy()\n",
        "new_line['Dist_A'] = 'GNU.000'\n",
        "#new_line['Dist_B'] = str(len(run_list))+' GNU'\n",
        "new_line['Dist_B'] = str(len(run_list))+' Intel'\n",
        "new_line['KS-stats'] = round(res[0],2)\n",
        "new_line['KS-pvalue'] = round(res[1],2)\n",
        "new_line['KL-entropy'] = round(Sp,2)\n",
        "new_line['KL-div'] = round(kl_res,2)\n",
        "summary_stat = summary_stat.append(new_line,ignore_index = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh8qQA9VOXb-"
      },
      "source": [
        "#summary_stat = summary_stat.drop(axis=1,columns=['KL-entropy'])\n",
        "summary_stat[['Dist_A','Dist_B','KS-stats','KS-pvalue','KL-div']].transpose()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVGTJydQyQcN"
      },
      "source": [
        "ens_df = df[(df.Label == 'Intel') & (df.nyear >= nyear - use_year)]\n",
        "add_test_df =  df[(df.Label == 'Intel') & (df.Simulation == '001')  & (df.nyear >= nyear - use_year)]\n",
        "my_var='TS'\n",
        "alpha = 0.05\n",
        "\n",
        "def stats_table(my_var,ens_df,add_test_df):\n",
        "  # my_var is for the variable to show\n",
        "  # add_test_df is the one member to add to comparison (in addition to all Test Simulations)\n",
        "  # ens_df is the ensemble to test against (Dist B)\n",
        "  res = stats.ks_2samp(gnu_df[my_var],intel_df[my_var])\n",
        "  ### Test all test runs\n",
        "  summary_stat = pd.DataFrame()\n",
        "  one_line = {\n",
        "      'Dist_A':'',\n",
        "      'Dist_B':'',\n",
        "      'KS-stats':0,\n",
        "      'KS-pvalue':0,\n",
        "      'KL-div':0,\n",
        "      'KL-entropy':0\n",
        "  }\n",
        "  test_list\n",
        "  run_list = np.unique(ens_df.Simulation)\n",
        "\n",
        "  for my_test in test_list:\n",
        "    new_line = one_line.copy()\n",
        "    test_df = df[df.Simulation == my_test]\n",
        "    # Change to Intel to test against Intel Ensemble\n",
        "    x = np.array(ens_df[my_var])\n",
        "    y = np.array(test_df[my_var])\n",
        "    bins = np.linspace(np.nanmin(np.hstack((x,y))),np.nanmax(np.hstack((x,y))),40)\n",
        "\n",
        "\n",
        "    p = np.histogram(x,bins = bins)[0]\n",
        "    q = np.histogram(y,bins = bins)[0]\n",
        "    #p = plt.hist(x,bins=bins)[0]\n",
        "    #q = plt.hist(y,bins=bins)[0]\n",
        "    p = p/p.sum(axis=0, keepdims=True) \n",
        "    q = q/q.sum(axis=0, keepdims=True) \n",
        "\n",
        "    #print('This is test run: ',my_test)\n",
        "    res = stats.ks_2samp(x,y)\n",
        "    #print('KS-statistics: ',res)\n",
        "    Sp = stats.entropy(np.array(x))\n",
        "    #print('KL-entropy of A: ',Sp)\n",
        "    kl_res = KL(p,q)\n",
        "    #print('KL-divergence: ',kl_res)\n",
        "    new_line['Dist_A'] = my_test\n",
        "    new_line['Dist_B'] = str(len(run_list))+' '+str(ens_df.Label.iloc[0])\n",
        "    new_line['KS-stats'] = round(res[0],2)\n",
        "    new_line['KS-pvalue'] = round(res[1],2)\n",
        "    new_line['KL-entropy'] = round(Sp,2)\n",
        "    new_line['KL-div'] = round(kl_res,2)\n",
        "\n",
        "    summary_stat = summary_stat.append(new_line,ignore_index = True)\n",
        "\n",
        "  ### Add GNU 000 for referencfe\n",
        "  x = np.array(ens_df[my_var])\n",
        "  y = np.array(add_test_df[my_var])\n",
        "  bins = np.linspace(np.nanmin(np.hstack((x,y))),np.nanmax(np.hstack((x,y))),40)\n",
        "  \n",
        "  #p = plt.hist(x,bins=bins)[0]\n",
        "  #q = plt.hist(y,bins=bins)[0]\n",
        "  p = np.histogram(x,bins = bins)[0]\n",
        "  q = np.histogram(y,bins = bins)[0]\n",
        "  p = p/p.sum(axis=0, keepdims=True) \n",
        "  q = q/q.sum(axis=0, keepdims=True) \n",
        "  #z = np.array(test_df[my_var])\n",
        "\n",
        "\n",
        "\n",
        "  # Note slight difference in the final result compared to Dawny33\n",
        "  #print('This is GNU.000')\n",
        "  res = stats.ks_2samp(x,y)\n",
        "  #print('KS-statistics: ',res)\n",
        "  #kl_res = scipy.special.kl_div(x,y)\n",
        "  kl_res = KL(p,q)\n",
        "  Sp = stats.entropy(np.array(x))\n",
        "  #print('KL-entropy of A: ',Sp)\n",
        "  #print('KL-divergence: ',kl_res)\n",
        "\n",
        "  new_line = one_line.copy()\n",
        "  new_line['Dist_A'] = str(add_test_df.Label.iloc[0])+'.'+str(add_test_df.Simulation.iloc[0])\n",
        "  new_line['Dist_B'] = str(len(run_list))+' '+str(ens_df.Label.iloc[0])\n",
        "  new_line['KS-stats'] = round(res[0],2)\n",
        "  new_line['KS-pvalue'] = round(res[1],2)\n",
        "  new_line['KL-entropy'] = round(Sp,2)\n",
        "  new_line['KL-div'] = round(kl_res,2)\n",
        "  \n",
        "\n",
        "  summary_stat = summary_stat.append(new_line,ignore_index = True)\n",
        "  print('Reject Null Hypothesis ('+str(alpha*100)+'% Confidence level) if D > ',round(np.sqrt(-np.log(alpha/2)/2)*np.sqrt(2600/2500/100),3))\n",
        "  return summary_stat[['Dist_A','Dist_B','KS-stats','KS-pvalue','KL-div']].transpose()\n",
        "\n",
        "stats_table(my_var,ens_df,add_test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awFU2hWdza3Y"
      },
      "source": [
        "var_list = column_list\n",
        "my_label = 'Intel'\n",
        "#add_test_df = df[(df.Label == my_label) & (df.Simulation.isin(['001']))  & (df.nyear >= nyear - use_year)]\n",
        "add_test_df = df[(df.Label == 'GNU') & (df.Simulation.isin(['001']))  & (df.nyear >= nyear - use_year)]\n",
        "ens_df = df[(df.Label == my_label)  & (df.nyear >= nyear - use_year)]\n",
        "\n",
        "\n",
        "\n",
        "@interact(my_var=var_list)\n",
        "def make_table_for(my_var='TS'):\n",
        "    my_stats_table = stats_table(my_var,ens_df,add_test_df)\n",
        "    display(my_stats_table)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyD0gCDsSOT1"
      },
      "source": [
        "distribution of KL and KS.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOyHjCesDDqV"
      },
      "source": [
        "ens_df.SNOWHICE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGYdXsfYaixj"
      },
      "source": [
        "#### KL Divergence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DIPZKKMg3yp"
      },
      "source": [
        "Test against Gaussian. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dZ3dUOHg15B"
      },
      "source": [
        "\n",
        "ens_df = gnu_df\n",
        "add_test_df =  df[(df.Label == 'GNU') & (df.Simulation == '004')]\n",
        "my_var='TS'\n",
        "\n",
        "def stats_table(my_var,ens_df,add_test_df):\n",
        "  # my_var is for the variable to show\n",
        "  # add_test_df is the one member to add to comparison (in addition to all Test Simulations)\n",
        "  # ens_df is the ensemble to test against (Dist B)\n",
        "  res = stats.ks_2samp(gnu_df[my_var],intel_df[my_var])\n",
        "  ### Test all test runs\n",
        "  summary_stat = pd.DataFrame()\n",
        "  one_line = {\n",
        "      'Dist_A':'',\n",
        "      'Dist_B':'',\n",
        "      'KS-stats':0,\n",
        "      'KS-pvalue':0,\n",
        "      'KL-div':0,\n",
        "      'KL-entropy':0\n",
        "  }\n",
        "  test_list\n",
        "  run_list = np.unique(ens_df.Simulation)\n",
        "\n",
        "  for my_test in test_list:\n",
        "    new_line = one_line.copy()\n",
        "    test_df = df[df.Simulation == my_test]\n",
        "    # Change to Intel to test against Intel Ensemble\n",
        "    x = np.array(ens_df[my_var])\n",
        "    y = np.array(test_df[my_var])\n",
        "    bins = np.linspace(np.nanmin(np.hstack((x,y))),np.nanmax(np.hstack((x,y))),40)\n",
        "\n",
        "\n",
        "    p = np.histogram(x,bins = bins)[0]\n",
        "    q = np.histogram(y,bins = bins)[0]\n",
        "    #p = plt.hist(x,bins=bins)[0]\n",
        "    #q = plt.hist(y,bins=bins)[0]\n",
        "    p = p/p.sum(axis=0, keepdims=True) \n",
        "    q = q/q.sum(axis=0, keepdims=True) \n",
        "\n",
        "    #print('This is test run: ',my_test)\n",
        "    res = stats.ks_2samp(x,y)\n",
        "    #print('KS-statistics: ',res)\n",
        "    Sp = stats.entropy(np.array(x))\n",
        "    #print('KL-entropy of A: ',Sp)\n",
        "    kl_res = KL(p,q)\n",
        "    #print('KL-divergence: ',kl_res)\n",
        "    new_line['Dist_A'] = my_test\n",
        "    new_line['Dist_B'] = str(len(run_list))+' '+str(ens_df.Label.iloc[0])\n",
        "    new_line['KS-stats'] = round(res[0],2)\n",
        "    new_line['KS-pvalue'] = round(res[1],2)\n",
        "    new_line['KL-entropy'] = round(Sp,2)\n",
        "    new_line['KL-div'] = round(kl_res,2)\n",
        "\n",
        "    summary_stat = summary_stat.append(new_line,ignore_index = True)\n",
        "\n",
        "  ### Add GNU 000 for referencfe\n",
        "  x = np.array(ens_df[my_var])\n",
        "  y = np.array(add_test_df[my_var])\n",
        "  bins = np.linspace(np.nanmin(np.hstack((x,y))),np.nanmax(np.hstack((x,y))),40)\n",
        "  \n",
        "  #p = plt.hist(x,bins=bins)[0]\n",
        "  #q = plt.hist(y,bins=bins)[0]\n",
        "  p = np.histogram(x,bins = bins)[0]\n",
        "  q = np.histogram(y,bins = bins)[0]\n",
        "  p = p/p.sum(axis=0, keepdims=True) \n",
        "  q = q/q.sum(axis=0, keepdims=True) \n",
        "  #z = np.array(test_df[my_var])\n",
        "\n",
        "\n",
        "\n",
        "  # Note slight difference in the final result compared to Dawny33\n",
        "  #print('This is GNU.000')\n",
        "  res = stats.ks_2samp(x,y)\n",
        "  #print('KS-statistics: ',res)\n",
        "  #kl_res = scipy.special.kl_div(x,y)\n",
        "  kl_res = KL(p,q)\n",
        "  Sp = stats.entropy(np.array(x))\n",
        "  #print('KL-entropy of A: ',Sp)\n",
        "  #print('KL-divergence: ',kl_res)\n",
        "\n",
        "  new_line = one_line.copy()\n",
        "  new_line['Dist_A'] = str(ens_df.Label.iloc[0])+'.'+str(add_test_df.Simulation.iloc[0])\n",
        "  new_line['Dist_B'] = str(len(run_list))+' '+str(ens_df.Label.iloc[0])\n",
        "  new_line['KS-stats'] = round(res[0],2)\n",
        "  new_line['KS-pvalue'] = round(res[1],2)\n",
        "  new_line['KL-entropy'] = round(Sp,2)\n",
        "  new_line['KL-div'] = round(kl_res,2)\n",
        "  \n",
        "\n",
        "  summary_stat = summary_stat.append(new_line,ignore_index = True)\n",
        "  return summary_stat[['Dist_A','Dist_B','KS-stats','KS-pvalue','KL-div']].transpose()\n",
        "\n",
        "stats_table(my_var,ens_df,add_test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqOZ_FRcoeJn"
      },
      "source": [
        "https://stats.stackexchange.com/questions/111445/analysis-of-kullback-leibler-divergence\n",
        "\n",
        "https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhfk-yhbbpP_"
      },
      "source": [
        "x = np.array(intel_df[my_var])\n",
        "y = np.array(gnu_df[my_var])\n",
        "# Normalize to pdf\n",
        "bins = np.linspace(np.nanmin(np.hstack((x,y))),np.nanmax(np.hstack((x,y))),40)\n",
        " \n",
        "p = plt.hist(x,bins=bins)[0]\n",
        "q = plt.hist(y,bins=bins)[0]\n",
        "p = p/p.sum(axis=0, keepdims=True) \n",
        "q = q/q.sum(axis=0, keepdims=True) \n",
        "#z = np.array(test_df[my_var])\n",
        "\n",
        "S = stats.entropy(p,q)\n",
        "#kl_res = scipy.special.kl_div(p,q)\n",
        "kl_res = KL(p,q)\n",
        "Sp = stats.entropy(p)\n",
        "Sq = stats.entropy(q)\n",
        "\n",
        "print(Sp,Sq,kl_res)\n",
        "\n",
        "fig = plt.figure(3)\n",
        "#plt.hist(x, bins=bins, density=True, histtype='step', cumulative=False,\n",
        "#        label='Intel',lw=2)\n",
        "#plt.hist(y, bins=bins, density=True, histtype='step', cumulative=False,\n",
        "#        label='GNU',lw=2)\n",
        "#plt.hist(kl_res,bins=bins, density=True, histtype='step', cumulative=False,\n",
        "#        label='KL Div',lw=2)\n",
        "sns.distplot(x, hist = False, kde = True,\n",
        "                 kde_kws = {'linewidth': 2},\n",
        "                 label = 'Intel')\n",
        "\n",
        "sns.distplot(y, hist = False, kde = True,\n",
        "                 kde_kws = {'linewidth': 2},\n",
        "                 label = 'GNU')\n",
        "\n",
        "plt.legend()\n",
        "#plt.title('KL(P||Q) = %1.2f' % S)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56wTeMiLsK0V"
      },
      "source": [
        "#### DataFrame for KS-stats and KL-div\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwRnv6DisOgs"
      },
      "source": [
        "ens_df = intel_df\n",
        "add_test_df =  df[(df.Label == 'GNU')]\n",
        "my_var='TS'\n",
        "\n",
        "def stats_table(my_var,ens_df,add_test_df):\n",
        "  # my_var is for the variable to show\n",
        "  # add_test_df is the one member to add to comparison (in addition to all Test Simulations)\n",
        "  # ens_df is the ensemble to test against (Dist B)\n",
        "  res = stats.ks_2samp(gnu_df[my_var],intel_df[my_var])\n",
        "  ### Test all test runs\n",
        "  summary_stat = pd.DataFrame()\n",
        "  one_line = {\n",
        "      'Dist_A':'',\n",
        "      'Dist_B':'',\n",
        "      'KS-stats':0,\n",
        "      'KS-pvalue':0,\n",
        "      'KL-div':0,\n",
        "      'KL-entropy':0\n",
        "  }\n",
        "  test_list\n",
        "  run_list = np.unique(ens_df.Simulation)\n",
        "\n",
        "  for my_test in test_list:\n",
        "    new_line = one_line.copy()\n",
        "    test_df = df[df.Simulation == my_test]\n",
        "    # Change to Intel to test against Intel Ensemble\n",
        "    x = np.array(ens_df[my_var])\n",
        "    y = np.array(test_df[my_var])\n",
        "    bins = np.linspace(np.nanmin(np.hstack((x,y))),np.nanmax(np.hstack((x,y))),40)\n",
        "\n",
        "\n",
        "    p = np.histogram(x,bins = bins)[0]\n",
        "    q = np.histogram(y,bins = bins)[0]\n",
        "    #p = plt.hist(x,bins=bins)[0]\n",
        "    #q = plt.hist(y,bins=bins)[0]\n",
        "    p = p/p.sum(axis=0, keepdims=True) \n",
        "    q = q/q.sum(axis=0, keepdims=True) \n",
        "\n",
        "    #print('This is test run: ',my_test)\n",
        "    res = stats.ks_2samp(x,y)\n",
        "    #print('KS-statistics: ',res)\n",
        "    Sp = stats.entropy(np.array(x))\n",
        "    #print('KL-entropy of A: ',Sp)\n",
        "    kl_res = KL(p,q)\n",
        "    #print('KL-divergence: ',kl_res)\n",
        "    new_line['Dist_A'] = my_test\n",
        "    new_line['Dist_B'] = str(len(run_list))+' '+str(ens_df.Label.iloc[0])\n",
        "    new_line['KS-stats'] = round(res[0],2)\n",
        "    new_line['KS-pvalue'] = round(res[1],2)\n",
        "    new_line['KL-entropy'] = round(Sp,2)\n",
        "    new_line['KL-div'] = round(kl_res,2)\n",
        "\n",
        "    summary_stat = summary_stat.append(new_line,ignore_index = True)\n",
        "\n",
        "  #simu_list = np.unique(ens_df.Simulation)\n",
        "  simu_list = ['001']\n",
        "  ### Add GNU 000 for referencfe\n",
        "  for my_simu in simu_list:\n",
        "    add_test_df = add_test_df#ens_df[ens_df.Simulation == my_simu]\n",
        "    x = np.array(ens_df[my_var])\n",
        "    y = np.array(add_test_df[my_var])\n",
        "    bins = np.linspace(np.nanmin(np.hstack((x,y))),np.nanmax(np.hstack((x,y))),40)\n",
        "    \n",
        "    #p = plt.hist(x,bins=bins)[0]\n",
        "    #q = plt.hist(y,bins=bins)[0]\n",
        "    p = np.histogram(x,bins = bins)[0]\n",
        "    q = np.histogram(y,bins = bins)[0]\n",
        "    p = p/p.sum(axis=0, keepdims=True) \n",
        "    q = q/q.sum(axis=0, keepdims=True) \n",
        "    #z = np.array(test_df[my_var])\n",
        "\n",
        "\n",
        "\n",
        "    # Note slight difference in the final result compared to Dawny33\n",
        "    #print('This is GNU.000')\n",
        "    res = stats.ks_2samp(x,y)\n",
        "    #print('KS-statistics: ',res)\n",
        "    #kl_res = scipy.special.kl_div(x,y)\n",
        "    kl_res = KL(p,q)\n",
        "    Sp = stats.entropy(np.array(x))\n",
        "    #print('KL-entropy of A: ',Sp)\n",
        "    #print('KL-divergence: ',kl_res)\n",
        "\n",
        "    new_line = one_line.copy()\n",
        "    new_line['Dist_A'] = str(ens_df.Label.iloc[0])+'.'+str(add_test_df.Simulation.iloc[0])\n",
        "    new_line['Dist_B'] = str(len(run_list))+' '+str(ens_df.Label.iloc[0])\n",
        "    new_line['KS-stats'] = round(res[0],2)\n",
        "    new_line['KS-pvalue'] = round(res[1],2)\n",
        "    new_line['KL-entropy'] = round(Sp,2)\n",
        "    new_line['KL-div'] = round(kl_res,2)\n",
        "    \n",
        "\n",
        "    summary_stat = summary_stat.append(new_line,ignore_index = True)\n",
        "  return summary_stat#[['Dist_A','Dist_B','KS-stats','KS-pvalue','KL-div']].transpose()\n",
        "\n",
        "summary_stat[['Dist_A','Dist_B','KS-stats','KS-pvalue','KL-div']].transpose()\n",
        "my_stat = stats_table(my_var,ens_df,add_test_df)\n",
        "ens_stat = my_stat[my_stat.Dist_A.str.contains('Intel')]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXNyjCH-2IPK"
      },
      "source": [
        "ens_stat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-j1aLFXtkVE"
      },
      "source": [
        "### Plot the distribution of three stats in three subplots\n",
        "fig = plt.figure(figsize = (8,8))\n",
        "for idx,my_stat in enumerate(['KS-stats','KS-pvalue','KL-div']):\n",
        "  ax = plt.subplot(2,2,idx+1)\n",
        "  #ax.set_title(my_stat)\n",
        "  x = ens_stat[my_stat]\n",
        "  bins = np.linspace(np.nanmin(x),np.nanmax(x),10)\n",
        "  sns.distplot(x,bins= bins)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCvzcaO7xp9j"
      },
      "source": [
        "newdf = pd.DataFrame()\n",
        "ens_df = intel_df\n",
        "add_test_df =  df[(df.Label == 'GNU')]\n",
        "for my_var in column_list:\n",
        "  stat_df = stats_table(my_var,ens_df,add_test_df)\n",
        "  stat_df['Variable'] = my_var\n",
        "  newdf = newdf.append(stat_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci4mtvBj2HWC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7ns3MYD2Vgp"
      },
      "source": [
        "\n",
        "for itest, my_test in enumerate(test_list):\n",
        "  subset = newdf[newdf.Dist_A.str.contains(my_test)]\n",
        "  print('% rejections of ',my_test)\n",
        "  print(len(subset[subset['KS-pvalue'] < ci])*1./len(subset))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxLShVv7FK6A"
      },
      "source": [
        "my_test = test_list[1]\n",
        "for my_var in column_list:\n",
        "  subset = newdf[~(newdf.Dist_A.str.contains('Intel')) & (newdf['Variable'] == my_var)]\n",
        "  if len(subset[subset['KS-pvalue'] < ci]) == 0:\n",
        "    print(my_var)\n",
        "    #print(subset[subset['KS-pvalue'] < ci].Dist_A)\n",
        "    #print(len(subset[subset['KS-pvalue'] < ci]))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuvPCbd92sZB"
      },
      "source": [
        "#### Plot heatmap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeiXM8W52sCP"
      },
      "source": [
        "newdf.replace(to_replace='Intel.000',value = 'GNU',inplace =True)\n",
        "newdf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1EYRUJ8GmYx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO5RW9-I5bKU"
      },
      "source": [
        "### Draw heatmap:\n",
        "remove_added = False\n",
        "\n",
        "data_df = newdf.pivot_table(values = 'KS-pvalue',index = 'Variable',columns='Dist_A')\n",
        "if remove_added:\n",
        "  data_df = data_df.drop(columns = 'GNU')\n",
        "  new_test_list = ['rh-min-low', 'albice00', 'cpl-bug','0nu', 'fma','expand',  'no-opt', 'rand-mt']\n",
        "else:\n",
        "  new_test_list = ['rh-min-low', 'albice00', 'cpl-bug','0nu', 'fma','expand',  'no-opt', 'rand-mt','GNU']\n",
        "\n",
        "var_df_removed = var_df[var_df.variable.isin(removed_column_list)].drop(columns=['Unnamed: 0','index'])\n",
        "var_df_removed['Variable'] = var_df_removed['variable']\n",
        "data_df = pd.merge(data_df,var_df_removed,on = 'Variable')\n",
        "data_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdHLU0O585Ax"
      },
      "source": [
        "\n",
        "my_type_list = np.unique(data_df['my_type'])\n",
        "mapping = {'Aerosol':1,'Precipitation':2,'Cloud':3,'Temperature':4,'Pressure':5,'Flux':6,'Fraction':7,'Height':8,'Transport':9}\n",
        "data_df['my_color'] = data_df['my_type'].map(mapping)\n",
        "#newdf['my_color'] = newdf['my_type'].map(lambda x, y: y, my_type_list, range(9))\n",
        "my_type_list = [my_type for my_type in mapping]\n",
        "my_type_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unCaEjHV3QzA"
      },
      "source": [
        "#data = np.random.randn(6, 6)\n",
        "nvar = len(removed_column_list)\n",
        "nmodes = len(new_test_list)\n",
        "\n",
        "data = np.zeros((nvar,nmodes))\n",
        "ks_array = np.zeros((nvar,nmodes))\n",
        "\n",
        "for itest,my_test in enumerate(new_test_list):\n",
        "  #data_df\n",
        "  df_reorder = data_df.sort_values(by = my_test,ascending=True)\n",
        "  data[:,itest] = df_reorder['my_color']\n",
        "  ks_array[:,itest] = df_reorder[my_test]\n",
        "  #my_sig = 'pc_sig'+str(imode+1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rri7_kG-7HDA"
      },
      "source": [
        "#data[:,0]\n",
        "ks_array[:,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HotI4KZe6baa"
      },
      "source": [
        "from matplotlib.colors import from_levels_and_colors\n",
        "from matplotlib.colorbar import ColorbarBase\n",
        "from matplotlib import colors\n",
        "import matplotlib as mpl\n",
        "from skimage.segmentation import mark_boundaries\n",
        "if remove_added:\n",
        "  fig, ax = plt.subplots(figsize=(10,10))\n",
        "  #cmap= colors.ListedColormap(['#fee0b6','#2166ac','#67a9cf','#b2182b','#984ea3','#fc8d59','#999999','#7fbf7b','#e0e0e0'])\n",
        "\n",
        "  cmap= colors.ListedColormap(['#fee0b6','#2166ac','#67a9cf','#b2182b','#984ea3','#fc8d59','#999999','#bababa','#31a354'])\n",
        "  bounds = np.arange(0.,10.,1)\n",
        "  norm = colors.BoundaryNorm(bounds, cmap.N, clip=True)\n",
        "\n",
        "\n",
        "  #plt.cm.PiYG\n",
        "  '''\n",
        "  qrates = np.array(my_type_list)\n",
        "  norm = mpl.colors.BoundaryNorm(np.linspace(1, 10, 10), 9)\n",
        "  fmt = mpl.ticker.FuncFormatter(lambda x, pos: qrates[:][norm(x)])\n",
        "\n",
        "  x = np.arange(0.5,10.5,10)\n",
        "  im = ax.imshow(data, cmap=cmap,  norm = norm, extent=[0.5,9.5,len(removed_column_list)+0.5,-0.5])\n",
        "  ax.contourf(alpha_array, 1, hatches=['//', ''], alpha=0,extent=[0.5,9.5,-0.5,len(removed_column_list)+0.5])\n",
        "  '''\n",
        "  new_alpha = ks_array.copy()\n",
        "  new_alpha = np.vstack((new_alpha[0,:],new_alpha,new_alpha[-1,:]))\n",
        "  new_alpha = np.hstack((new_alpha[:,0].reshape(len(new_alpha),1),new_alpha,new_alpha[:,-1].reshape(len(new_alpha),1)))\n",
        "  my_shape = np.shape(new_alpha)\n",
        "\n",
        "  qrates = np.array(my_type_list)\n",
        "  norm = mpl.colors.BoundaryNorm(np.linspace(1, 10, 10), 9)\n",
        "  fmt = mpl.ticker.FuncFormatter(lambda x, pos: qrates[:][norm(x)])\n",
        "\n",
        "\n",
        "\n",
        "  im = ax.imshow(data, cmap=cmap,  norm = norm)#, extent=[0.5,9.5,len(removed_column_list)+0.5,-0.5])\n",
        "  ax.contourf(new_alpha < 0.05, 1, hatches=['//', ''], alpha=0,origin = 'image',extent=[-1.5,8.5,len(removed_column_list)+1.5,-1.5])\n",
        "  ax.set_xlim(-0.5,7.5)\n",
        "  ax.set_ylim(len(removed_column_list)-0.5,-0.5)\n",
        "\n",
        "  ax.set_xticks(range(8))\n",
        "  #ax.set_xticklabels(labels=[str(imode+1) for imode in range(8)])\n",
        "  ax.set_xticklabels(labels=new_test_list,rotation=45)\n",
        "\n",
        "  ax.set_xlabel('Test runs') ## Zero means largest PC mode\n",
        "\n",
        "  ax.set_ylabel('Ascending order of KS test p-values') ## Zero means largest PC mode\n",
        "  ax.set_aspect(0.1)\n",
        "\n",
        "\n",
        "  cbar_kw=dict(ticks=np.arange(0.5, 10.5,1), format=fmt,norm=norm)\n",
        "  cbar = ax.figure.colorbar(im,  **cbar_kw)\n",
        "  cbar.ax.set_ylabel(\"Type\", rotation=-90, va=\"bottom\",fontsize = 12)\n",
        "\n",
        "  plt.savefig(local_dir+'KS_test_runs_physics.png',dpi = 500)\n",
        "else:\n",
        "  print('KS heatmap not shown')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riPPoIKDEqD3"
      },
      "source": [
        "HEatmap, sorted by type, colored by KS pvalue. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3TJX7A9FWX2"
      },
      "source": [
        "data_df['sort_order'] = 8\n",
        "data_df['sort_order'].loc[data_df.my_type == 'Flux'] = 0\n",
        "data_df['sort_order'].loc[data_df.my_type == 'Cloud'] = 1\n",
        "data_df['sort_order'].loc[data_df.my_type == 'Aerosol'] = 2\n",
        "data_df['sort_order'].loc[data_df.my_type == 'Precipitation'] = 3\n",
        "data_df['sort_order'].loc[data_df.my_type == 'Height'] = 4\n",
        "data_df['sort_order'].loc[data_df.my_type == 'Temperature'] = 5\n",
        "data_df['sort_order'].loc[data_df.my_type == 'Pressure'] = 6\n",
        "data_df['sort_order'].loc[data_df.my_type == 'Transport'] = 7\n",
        "\n",
        "data_df = data_df.sort_values(by=['sort_order','my_type'])\n",
        "data_df = data_df.reset_index()\n",
        "\n",
        "data_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyeNy1qsEpgy"
      },
      "source": [
        "remove_var = True\n",
        "\n",
        "var_df = pd.read_csv(local_dir+'CESM_variable_type.csv')\n",
        "var_df['my_type'] = var_df['type']\n",
        "new_var_df = var_df.copy()\n",
        "new_var_df['sort_order'] = 8\n",
        "new_var_df['sort_order'].loc[new_var_df.my_type == 'Flux'] = 0\n",
        "new_var_df['sort_order'].loc[new_var_df.my_type == 'Cloud'] = 1\n",
        "new_var_df['sort_order'].loc[new_var_df.my_type == 'Aerosol'] = 2\n",
        "new_var_df['sort_order'].loc[new_var_df.my_type == 'Precipitation'] = 3\n",
        "new_var_df['sort_order'].loc[new_var_df.my_type == 'Height'] = 4\n",
        "new_var_df['sort_order'].loc[new_var_df.my_type == 'Temperature'] = 5\n",
        "new_var_df['sort_order'].loc[new_var_df.my_type == 'Pressure'] = 6\n",
        "new_var_df['sort_order'].loc[new_var_df.my_type == 'Transport'] = 7\n",
        "\n",
        "nine_type_list = ['Flux','Cloud','Aerosol','Precipitation','Height','Temperature','Pressure','Transport','Fraction']\n",
        "\n",
        "new_var_df = new_var_df.sort_values(by=['sort_order','my_type'])\n",
        "new_var_df = new_var_df.reset_index()\n",
        "sorted_column_list = new_var_df.variable\n",
        "sorted_type_list = new_var_df.my_type\n",
        "\n",
        "sorted_column_list = list(sorted_column_list)\n",
        "# Remove three variables with bump start: 'OCNFRAC','ICEFRAC','SNOWHICE'\n",
        "# Remove three constant variables: 'LANDFRAC','PHIS','SOLIN'\n",
        "#remove_var_list =  ['OCNFRAC','ICEFRAC','SNOWHICE','LANDFRAC','PHIS','SOLIN']\n",
        "#remove_var_list =  ['EMISCLD','OCNFRAC','ICEFRAC','SNOWHICE','LANDFRAC','PHIS','SOLIN']\n",
        "for my_col in remove_var_list:\n",
        "  sorted_column_list.remove(my_col)\n",
        "np.array(sorted_column_list,dtype=str)\n",
        "\n",
        "if remove_var:\n",
        "  column_list = sorted_column_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3kRg8kaE-n1"
      },
      "source": [
        "#data = np.random.randn(6, 6)\n",
        "nvar = len(removed_column_list)\n",
        "nmodes = len(new_test_list)\n",
        "\n",
        "data = np.zeros((nvar,nmodes))\n",
        "ks_array = np.zeros((nvar,nmodes))\n",
        "\n",
        "for itest,my_test in enumerate(new_test_list):\n",
        "  #data_df\n",
        "  df_reorder = data_df.copy()#.sort_values(by = my_test,ascending=True)\n",
        "  data[:,itest] = df_reorder['my_color']\n",
        "  ks_array[:,itest] = df_reorder[my_test]\n",
        "  #my_sig = 'pc_sig'+str(imode+1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqqcXMjuD5z0"
      },
      "source": [
        "### Color coding by KS p-value\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "#YlBu = np.array(['#ffffd9','#edf8b1','#c7e9b4','#7fcdbb','#41b6c4','#1d91c0','#225ea8','#0c2c84'])[::-1]\n",
        "#cmap= colors.ListedColormap(YlBu)\n",
        "#bounds = [0., 0.001, 0.005, 0.01,0.05,0.1,0.5,0.75,1.]\n",
        "\n",
        "YlBu = np.array(['#f7f7f7','#ffffd9','#edf8b1','#c7e9b4','#7fcdbb','#41b6c4','#1d91c0','#225ea8','#0c2c84'])[::-1]\n",
        "cmap= colors.ListedColormap(YlBu)\n",
        "bounds = [0., 0.001, 0.005, 0.01,0.05,0.1,0.2,0.5,0.9,1.]\n",
        "norm = colors.BoundaryNorm(bounds, cmap.N, clip=True)\n",
        "\n",
        "\n",
        "#plt.cm.PiYG\n",
        "'''\n",
        "qrates = np.array(my_type_list)\n",
        "norm = mpl.colors.BoundaryNorm(np.linspace(1, 10, 10), 9)\n",
        "fmt = mpl.ticker.FuncFormatter(lambda x, pos: qrates[:][norm(x)])\n",
        "\n",
        "x = np.arange(0.5,10.5,10)\n",
        "im = ax.imshow(data, cmap=cmap,  norm = norm, extent=[0.5,9.5,len(removed_column_list)+0.5,-0.5])\n",
        "ax.contourf(alpha_array, 1, hatches=['//', ''], alpha=0,extent=[0.5,9.5,-0.5,len(removed_column_list)+0.5])\n",
        "'''\n",
        "new_alpha = ks_array.copy()\n",
        "new_alpha = np.vstack((new_alpha[0,:],new_alpha,new_alpha[-1,:]))\n",
        "new_alpha = np.hstack((new_alpha[:,0].reshape(len(new_alpha),1),new_alpha,new_alpha[:,-1].reshape(len(new_alpha),1)))\n",
        "my_shape = np.shape(new_alpha)\n",
        "\n",
        "qrates = [str(my_cbar_tick) for my_cbar_tick in bounds]\n",
        "norm = mpl.colors.BoundaryNorm(bounds,9)\n",
        "fmt = mpl.ticker.FuncFormatter(lambda x, pos: qrates[:][norm(x)])\n",
        "\n",
        "\n",
        "#im = ax.imshow(ks_array, cmap= 'RdBu_r', vmin = 0., vmax = 1)#, extent=[0.5,9.5,len(removed_column_list)+0.5,-0.5])\n",
        "im = ax.imshow(ks_array, cmap= cmap, norm=norm)#, extent=[0.5,9.5,len(removed_column_list)+0.5,-0.5])\n",
        "#ax.contourf(new_alpha < 0.05, 1, hatches=['//', ''], alpha=0,origin = 'image',extent=[-1.5,8.5,len(removed_column_list)+1.5,-1.5])\n",
        "ax.set_xlim(-0.5,len(new_test_list)-0.5)\n",
        "ax.set_ylim(len(removed_column_list)-0.5,-0.5)\n",
        "\n",
        "ax.set_xticks(range(len(new_test_list)))\n",
        "#ax.set_xticklabels(labels=[str(imode+1) for imode in range(8)])\n",
        "ax.set_xticklabels(labels=new_test_list,rotation=45,fontsize = fs-1)\n",
        "ytick_locs = ([np.mean(np.array(data_df[data_df.my_type == my_type].index)) for my_type in (nine_type_list)])\n",
        "ytick_sep_locs = ([data_df[data_df.my_type == my_type].index[0]-0.5 for my_type in nine_type_list])\n",
        "ytick_sep_locs = list(ytick_sep_locs)\n",
        "ytick_sep_locs.append(ytick_sep_locs[-1]+1)\n",
        "ytick_labels = ([str(my_ytick) for my_ytick in nine_type_list ])\n",
        "\n",
        "ax.vlines([0.5,1.5,2.5,3.5,4.5,5.5,6.5],-0.5,127.5,linewidth=1)\n",
        "ax.vlines(3.5,-0.5,127.5,linewidth=2)\n",
        "if not remove_added:\n",
        "  ax.vlines(7.5,-0.5,127.5,linewidth=2)\n",
        "ax.hlines(ytick_sep_locs,-0.5,len(new_test_list)-0.5,linewidth=1)\n",
        "\n",
        "ax.set_xlabel('All runs',fontsize = fs) ## Zero means largest PC mode\n",
        "\n",
        "ax.set_ylabel('Variables ordered by type',fontsize = fs-2) ## Zero means largest PC mode\n",
        "ax.set_yticks(ytick_locs)\n",
        "ax.set_yticklabels(ytick_labels,fontsize = fs-1)\n",
        "ax.set_yticks(ytick_sep_locs,minor = True)\n",
        "ax.tick_params(axis='y', which='major',length=0)\n",
        "ax.tick_params(axis='y', which='minor',length=5)\n",
        "\n",
        "ax.set_aspect(0.1)\n",
        "\n",
        "\n",
        "#cbar_kw=dict(ticks=np.arange(0,1), format=fmt)\n",
        "cbar = ax.figure.colorbar(im)\n",
        "cbar.ax.set_ylabel(\"K-S p-value\", rotation=-90, va=\"bottom\",fontsize = fs-2)\n",
        "\n",
        "plt.savefig(local_dir+'KS_test_runs_physics.png',dpi = 500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyBhz6EAFrdw"
      },
      "source": [
        "### Version ordered by PC. \n",
        "sorted_column_list_pc = np.load(local_dir+'sorted_column_list_pc.npy')\n",
        "\n",
        "sorted_column_df = pd.DataFrame(sorted_column_list_pc,columns = ['variable'])\n",
        "new_data_df = sorted_column_df.merge(data_df,how = 'left')\n",
        "new_data_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKiALx-OSsKa"
      },
      "source": [
        "data_df[data_df.variable == 'FSDSC']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrXvuSIsGN4V"
      },
      "source": [
        "#data = np.random.randn(6, 6)\n",
        "nvar = len(removed_column_list)\n",
        "nmodes = len(new_test_list)\n",
        "\n",
        "data = np.zeros((nvar,nmodes))\n",
        "ks_array = np.zeros((nvar,nmodes))\n",
        "\n",
        "for itest,my_test in enumerate(new_test_list):\n",
        "  #data_df\n",
        "  df_reorder = new_data_df.copy()#.sort_values(by = my_test,ascending=True)\n",
        "  data[:,itest] = df_reorder['my_color']\n",
        "  ks_array[:,itest] = df_reorder[my_test]\n",
        "  #my_sig = 'pc_sig'+str(imode+1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81wgeCh4QG8n"
      },
      "source": [
        "my_test1 = new_test_list[5]\n",
        "my_test2 = new_test_list[2]\n",
        "print(my_test1,my_test2)\n",
        "np.array(data_df[(data_df[my_test1] < 0.001) & (data_df[my_test2] > 0.001)].variable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3JM5o2TK9IT"
      },
      "source": [
        "### KS p-value ordered by PC\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "\n",
        "YlBu = np.array(['#f7f7f7','#ffffd9','#edf8b1','#c7e9b4','#7fcdbb','#41b6c4','#1d91c0','#225ea8','#0c2c84'])[::-1]\n",
        "cmap= colors.ListedColormap(YlBu)\n",
        "bounds = [0., 0.001, 0.005, 0.01,0.05,0.1,0.2,0.5,0.9,1.]\n",
        "norm = colors.BoundaryNorm(bounds, cmap.N, clip=True)\n",
        "\n",
        "\n",
        "#plt.cm.PiYG\n",
        "'''\n",
        "qrates = np.array(my_type_list)\n",
        "norm = mpl.colors.BoundaryNorm(np.linspace(1, 10, 10), 9)\n",
        "fmt = mpl.ticker.FuncFormatter(lambda x, pos: qrates[:][norm(x)])\n",
        "\n",
        "x = np.arange(0.5,10.5,10)\n",
        "im = ax.imshow(data, cmap=cmap,  norm = norm, extent=[0.5,9.5,len(removed_column_list)+0.5,-0.5])\n",
        "ax.contourf(alpha_array, 1, hatches=['//', ''], alpha=0,extent=[0.5,9.5,-0.5,len(removed_column_list)+0.5])\n",
        "'''\n",
        "new_alpha = ks_array.copy()\n",
        "new_alpha = np.vstack((new_alpha[0,:],new_alpha,new_alpha[-1,:]))\n",
        "new_alpha = np.hstack((new_alpha[:,0].reshape(len(new_alpha),1),new_alpha,new_alpha[:,-1].reshape(len(new_alpha),1)))\n",
        "my_shape = np.shape(new_alpha)\n",
        "\n",
        "qrates = [str(my_cbar_tick) for my_cbar_tick in bounds]\n",
        "norm = mpl.colors.BoundaryNorm(bounds,len(YlBu))\n",
        "fmt = mpl.ticker.FuncFormatter(lambda x, pos: qrates[:][norm(x)])\n",
        "\n",
        "\n",
        "#im = ax.imshow(ks_array, cmap= 'RdBu_r', vmin = 0., vmax = 1)#, extent=[0.5,9.5,len(removed_column_list)+0.5,-0.5])\n",
        "im = ax.imshow(ks_array, cmap= cmap, norm=norm)#, extent=[0.5,9.5,len(removed_column_list)+0.5,-0.5])\n",
        "#ax.contourf(new_alpha < 0.05, 1, hatches=['//', ''], alpha=0,origin = 'image',extent=[-1.5,8.5,len(removed_column_list)+1.5,-1.5])\n",
        "ax.set_xlim(-0.5,len(new_test_list)-0.5)\n",
        "ax.set_ylim(len(removed_column_list)-0.5,-0.5)\n",
        "\n",
        "ax.set_xticks(range(len(new_test_list)))\n",
        "#ax.set_xticklabels(labels=[str(imode+1) for imode in range(8)])\n",
        "ax.set_xticklabels(labels=new_test_list,rotation=45)\n",
        "ytick_locs = list(np.arange(7.5,120,15) - 0.5)\n",
        "ytick_locs.append(123)\n",
        "\n",
        "ytick_sep_locs = np.arange(0,128,15) - 0.5\n",
        "\n",
        "ytick_labels = (['mode'+str(my_mode+1) for my_mode in range(9) ])\n",
        "\n",
        "ax.vlines([0.5,1.5,2.5,3.5,4.5,5.5,6.5],-0.5,127.5,linewidth=1)\n",
        "ax.vlines(3.5,-0.5,127.5,linewidth=2)\n",
        "if not remove_added:\n",
        "  ax.vlines(7.5,-0.5,127.5,linewidth=2)\n",
        "ax.hlines(ytick_sep_locs,-0.5,len(new_test_list)-0.5,linewidth=1)\n",
        "\n",
        "ax.set_xlabel('Test runs') ## Zero means largest PC mode\n",
        "\n",
        "ax.set_ylabel('Variables ordered by PC modes') ## Zero means largest PC mode\n",
        "ax.set_yticks(ytick_locs)\n",
        "ax.set_yticklabels(ytick_labels)\n",
        "ax.set_yticks(ytick_sep_locs,minor = True)\n",
        "ax.tick_params(axis='y', which='major',length=0)\n",
        "ax.tick_params(axis='y', which='minor',length=5)\n",
        "\n",
        "ax.set_aspect(0.1)\n",
        "\n",
        "\n",
        "#cbar_kw=dict(ticks=np.arange(0,1), format=fmt)\n",
        "cbar = ax.figure.colorbar(im)\n",
        "cbar.ax.set_ylabel(\"K-S p-value\", rotation=-90, va=\"bottom\",fontsize = 12)\n",
        "\n",
        "plt.savefig(local_dir+'KS_test_runs_physics_pc.png',dpi = 500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK8YCCv9ISrZ"
      },
      "source": [
        "np.unique([np.mean(np.array(data_df[data_df.my_type == my_type].index)) for my_type in (sorted_type_list)])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKkgmau8jAz0"
      },
      "source": [
        "## Testing same mean and variance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oj7g_wBjEyE"
      },
      "source": [
        "#### T-test for same mean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h6DlHkijLAo"
      },
      "source": [
        "\n",
        "for my_var in column_list:\n",
        "  X = intel_df[intel_df.Simulation != '000'][my_var]\n",
        "  Y = gnu_df[gnu_df.Simulation != '000'][my_var]\n",
        "  #Y = df[df.Simulation == my_test][my_var]\n",
        "  df1 = len(X) - 1\n",
        "  df2 = len(Y) - 1\n",
        "\n",
        "  alpha = 0.05 #Or whatever you want your alpha to be.\n",
        "  t_stat, p_value = scipy.stats.ttest_ind(X,Y)\n",
        "  if p_value < alpha:\n",
        "    print(my_var)\n",
        "    #print('Reject the hypothesis',my_var,p_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lkofQEAjIdv"
      },
      "source": [
        "#### F-test for same variance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ndggfpgniRm"
      },
      "source": [
        "test_df.Simulation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arv_FakXjVyo"
      },
      "source": [
        "my_test = test_list[7]\n",
        "print('Test run: ',my_test)\n",
        "for my_var in column_list:\n",
        "  X = intel_df[intel_df.Simulation != '000'][my_var]\n",
        "  #Y = gnu_df[gnu_df.Simulation != '000'][my_var]\n",
        "  Y = df[df.Simulation == my_test][my_var]\n",
        "  F = np.var(X) / np.var(Y)\n",
        "  df1 = len(X) - 1\n",
        "  df2 = len(Y) - 1\n",
        "\n",
        "  alpha = 0.05 #Or whatever you want your alpha to be.\n",
        "  p_value = scipy.stats.f.cdf(F, df1, df2)\n",
        "  if p_value < alpha:\n",
        "    print(my_var)\n",
        "    #print('Reject the hypothesis',my_var,p_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzMmIIVy8aWk"
      },
      "source": [
        "#### Year start to diverge?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJ3SJry-8eYr"
      },
      "source": [
        "Answering the question by Dorit: In which year does the difference start to show up? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QByzs5eY_cfy"
      },
      "source": [
        "# Always remove Intel 006\n",
        "matched = True\n",
        "if not matched:\n",
        "  gnu_df = df[(df.Label == 'GNU')]\n",
        "  intel_df = df[(df.Label == 'Intel')]\n",
        "  #intel_df = df[(df.Label == 'Intel') & (df.Simulation != '006')]\n",
        "  intel_perc = np.nanpercentile(df[(df.Label == 'Intel')][my_var],my_perc)\n",
        "else:\n",
        "  match_list = [str(simu).zfill(3) for simu in range(25)]\n",
        "  #match_list.remove('006')\n",
        "  gnu_df = df[(df.Label == 'GNU') & (df.Simulation.isin(match_list))]\n",
        "  intel_df = df[(df.Label == 'Intel') & (df.Simulation.isin(match_list))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDlPKtRb9BO4"
      },
      "source": [
        "sns.lineplot(x = \"nyear\", y = \"TS\", data = intel_df,label = 'Intel')\n",
        "sns.lineplot(x = \"nyear\", y = \"TS\", data = gnu_df,label='GNU')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oTF6n-XD55A"
      },
      "source": [
        "sns.lineplot(x = \"nyear\", y = \"TS\", data = intel_df,label = 'Intel')\n",
        "sns.lineplot(x = \"nyear\", y = \"TS\", data = df[df.Simulation == test_list[-1]],label=test_list[-1])\n",
        "plt.legend(frameon=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-muARjjMT7G"
      },
      "source": [
        "my_var = 'TS'\n",
        "ts = np.array(df[df.Simulation == test_list[-1]][my_var]) - intel_df.groupby('nyear')[my_var].mean()\n",
        "\n",
        "ts[abs(ts) > 0.05 ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KJGgBuGNVhZ"
      },
      "source": [
        "#### KS-test for each year GNU runs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84D_q8YhNaKG"
      },
      "source": [
        "intel_df = df[(df.Label == 'Intel') & (df.Simulation != '000') ]\n",
        "gnu_df = df[(df.Label == 'GNU') & (df.Simulation != '000')]\n",
        "intel_df.Simulation\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k4Vgarn8dhs"
      },
      "source": [
        "### How many variables fails the 5% KS-test in each year (or plot p-value across time)\n",
        "nyear = 100\n",
        "confidence_level = 0.05\n",
        "fail_ts = np.zeros(nyear)\n",
        "pvalue_ts = np.zeros(nyear)\n",
        "\n",
        "for yr in range(nyear):\n",
        "  num_fail = 0\n",
        "  pvalue_list = []\n",
        "  for my_var in column_list:\n",
        "    x = intel_df[(intel_df.nyear == yr)][my_var]\n",
        "    y = gnu_df[gnu_df.nyear == yr][my_var]\n",
        "    #y = df[(df.Simulation.str.contains(test_list[0]))][my_var]\n",
        "    ks_res = stats.ks_2samp(x,y)\n",
        "    pvalue = round(ks_res[1],2)\n",
        "    pvalue_list.append(pvalue)\n",
        "    if pvalue < confidence_level:\n",
        "      num_fail = num_fail+1\n",
        "      if yr <= 9:\n",
        "        print('This is year ',yr,my_var)\n",
        "  fail_ts[yr] = num_fail/134.\n",
        "  pvalue_ts[yr] = np.nanmean(pvalue_list)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iMZtKK5gS_T"
      },
      "source": [
        "fig = plt.figure(1,figsize = (8,10))\n",
        "ax= plt.subplot(2,1,1)\n",
        "sns.lineplot(range(nyear),fail_ts*100,label = 'GNU')\n",
        "plt.xlabel(\"Years\")\n",
        "plt.ylabel(\"Percent\")\n",
        "plt.legend(frameon=False)\n",
        "plt.title(\"Percent of variables failing  {:.2f} KS-test\".format(confidence_level))\n",
        "\n",
        "\n",
        "ax= plt.subplot(2,1,2)\n",
        "pvalue_std = np.nanstd(pvalue_ts)\n",
        "sns.lineplot(range(nyear),pvalue_ts,label = 'GNU')\n",
        "plt.xlabel(\"Years\")\n",
        "plt.ylabel(\"p-value\")\n",
        "plt.legend(frameon=False)\n",
        "plt.title(\"Mean p-value of KS-test\")\n",
        "plt.hlines(np.mean(pvalue_ts) + 1*pvalue_std,0,100,linestyle = '--')\n",
        "plt.hlines(np.mean(pvalue_ts) - 1*pvalue_std,0,100,linestyle = '--')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNd7lO9ZcVgm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nobxHkxV3eQk"
      },
      "source": [
        "for my_var in column_list:\n",
        "  num_fail = 0\n",
        "  for yr in range(nyear):\n",
        "    x = intel_df[(intel_df.nyear == yr)][my_var]\n",
        "    y = gnu_df[gnu_df.nyear == yr][my_var]\n",
        "    #y = df[(df.Simulation.str.contains(test_list[0]))][my_var]\n",
        "    ks_res = stats.ks_2samp(x,y)\n",
        "    pvalue = round(ks_res[1],2)\n",
        "    if pvalue < confidence_level:\n",
        "      num_fail = num_fail+1\n",
        "      #if yr <= 9:\n",
        "      #  print('This is year ',yr,my_var)\n",
        "  fail_ts[yr] = num_fail/100."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE4Yys-sOLBz"
      },
      "source": [
        "fail_ts\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwJDCo16NQ5J"
      },
      "source": [
        "#### Bootstrapping of time series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGQ8l_O78SRC"
      },
      "source": [
        "my_run = df[(df.Simulation == 'rh-min-low')]\n",
        "plt.plot(range(100),my_run['VT'],label='rh-min-low')\n",
        "\n",
        "my_intel = df[(df.Simulation == '001') & (df.Label == 'Intel')]\n",
        "plt.plot(range(100),my_intel['VT'],label='Intel.001')\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr8YElwYpk8r"
      },
      "source": [
        "### Shuffle Intel\n",
        "\n",
        "#plt.plot(range(100),my_run['VT'],label='rh-min-low')\n",
        "\n",
        "#my_intel = df[(df.Simulation == '001') & (df.Label == 'Intel')]\n",
        "#plt.plot(range(100),my_intel['VT'],label='Intel.001')\n",
        "\n",
        "\n",
        "fig = plt.figure(1,figsize = (12,6))\n",
        "mean_intel = []\n",
        "std_intel = []\n",
        "nyear = 100\n",
        "use_year = 100\n",
        "my_var = 'VT'\n",
        "intel_df = df[df.Label == 'Intel']\n",
        "nshuffle = 10\n",
        "div_year = int(use_year/2)\n",
        "\n",
        "my_test = 'rh-min-low'\n",
        "my_run = df[(df.Simulation == my_test) & (df.nyear >= nyear - use_year)]\n",
        "\n",
        "for my_simu in np.unique(intel_df.Simulation):\n",
        "  intel_ts = np.array(intel_df[(intel_df.Simulation == my_simu) & (intel_df.nyear >= nyear - use_year)][my_var])\n",
        "  for ishuffle in range(nshuffle):\n",
        "    np.random.shuffle(intel_ts)\n",
        "    new_ts = intel_ts.copy()\n",
        "    \n",
        "    mean_intel.append(np.nanmean(new_ts[:div_year])/np.nanmean(new_ts[div_year:]))\n",
        "    std_intel.append(np.nanstd(new_ts[:div_year])/np.nanstd(new_ts[div_year:]))\n",
        "\n",
        "### Shuffle rh-min-low\n",
        "mean_test = []\n",
        "std_test = []\n",
        "rh_ts = np.array(my_run['VT'])\n",
        "print(rh_ts)\n",
        "for ishuffle in range(1000):\n",
        "  np.random.shuffle(rh_ts)\n",
        "  new_ts = rh_ts.copy()\n",
        "  mean_test.append(np.nanmean(new_ts[:div_year])/np.nanmean(new_ts[div_year:]))\n",
        "  std_test.append(np.nanstd(new_ts[:div_year])/np.nanstd(new_ts[div_year:]))\n",
        "\n",
        "### plot figures\n",
        "ax = plt.subplot(1,2,1)\n",
        "mean_ratio = np.mean(my_run['VT'][div_year:])/np.mean(my_run['VT'][:div_year])\n",
        "std_ratio = np.std(my_run['VT'][div_year:])/np.std(my_run['VT'][:div_year])\n",
        "vmin = np.nanmin(np.hstack((mean_intel,mean_test)))\n",
        "vmax = np.nanmax(np.hstack((mean_intel,mean_test)))\n",
        "nbins = 16\n",
        "bins = np.linspace(vmin,vmax,nbins)\n",
        "ax.hist(mean_intel,bins,color = 'b',label = 'Intel',alpha = 0.4,density = True)\n",
        "ax.hist(mean_test,bins,color = 'orange',label = my_test,alpha = 0.4,density = True)\n",
        "ax.set_title('Mean')\n",
        "#p = plt.hist(mean_intel,bins=bins)[0]\n",
        "#q = plt.hist(mean_test,bins=bins)[0]\n",
        "#p = p/p.sum(axis=0, keepdims=True) \n",
        "#q = q/q.sum(axis=0, keepdims=True) \n",
        "\n",
        "#plt.hist(p,bins)\n",
        "#plt.hist(q,bins)\n",
        "ylim = plt.gca().get_ylim()\n",
        "plt.vlines(mean_ratio,0,ylim[1],linestyle = '--')\n",
        "\n",
        "\n",
        "ax = plt.subplot(1,2,2)\n",
        "vmin = np.nanmin(np.hstack((std_intel,std_test)))\n",
        "vmax = np.nanmax(np.hstack((std_intel,std_test)))\n",
        "bins = np.linspace(vmin,vmax,nbins)\n",
        "ax.set_title('Stddev')\n",
        "\n",
        "ax.hist(std_intel,bins,color = 'b',label = 'Intel',alpha = 0.4,density = True)\n",
        "ax.hist(std_test,bins,color = 'orange',label = my_test,alpha = 0.4,density = True)\n",
        "ylim = plt.gca().get_ylim()\n",
        "plt.vlines(std_ratio,0,ylim[1],linestyle = '--')\n",
        "\n",
        "plt.legend()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBRXbdBj8s8k"
      },
      "source": [
        "Randomly draw 10 years from the distribution, how likely  is the first 10 years of Intel/GNU/Test runs lie outside the distribution? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3X1Umea9MoF"
      },
      "source": [
        "len(var_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYGPD13h9KF6"
      },
      "source": [
        "### Shuffle Intel\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "my_test = 'rh-min-low'\n",
        "intel_df = df[df.Label == 'Intel']\n",
        "new_var_list = ['TS','TSMN','TSMX','VT','VU','U10','LWCF','BURDEN2','CCN3']\n",
        "#new_var_list[6] = 'SWCF'\n",
        "\n",
        "my_intel_simu = '001'\n",
        "\n",
        "\n",
        "first_nyears = 10\n",
        "\n",
        "fig = plt.figure(1,figsize = (12,12))\n",
        "\n",
        "#std_intel = []\n",
        "nyear = 100\n",
        "use_year = 90\n",
        "\n",
        "my_run = df[(df.Simulation == my_test) & (df.nyear >= nyear - use_year)]\n",
        "my_intel = intel_df[(intel_df.Simulation == my_intel_simu) & (intel_df.nyear >= nyear - use_year)]\n",
        "#my_var = 'BURDEN2'\n",
        "nshuffle = 10\n",
        "div_year = int(use_year/2)\n",
        "\n",
        "for ivar,my_var in enumerate(new_var_list):\n",
        "  ten_yr_intel = []\n",
        "  ax = plt.subplot(3,3,ivar+1)\n",
        "  for my_simu in np.unique(intel_df.Simulation):\n",
        "    intel_ts = np.array(intel_df[(intel_df.Simulation == my_simu) & (intel_df.nyear >= nyear - use_year)][my_var])\n",
        "    for ishuffle in range(nshuffle):\n",
        "      my_array = np.random.choice(range(use_year),first_nyears,replace = False)\n",
        "      new_ts = intel_ts.copy()    \n",
        "      ten_yr_intel.append(np.nanmean(new_ts[my_array]))\n",
        "\n",
        "  ### Shuffle rh-min-low\n",
        "  ten_yr_test = []\n",
        "  rh_ts = np.array(my_run[my_var])\n",
        "  print(rh_ts)\n",
        "  nshuffle_test = 100\n",
        "  for ishuffle in range(nshuffle_test):\n",
        "    my_array = np.random.choice(range(use_year),first_nyears,replace = False)\n",
        "    new_ts = rh_ts.copy()\n",
        "    ten_yr_test.append(np.nanmean(new_ts[my_array]))\n",
        "\n",
        "  ### plot figures\n",
        "  test_raw = np.nanmean(my_run[my_var][:first_nyears])\n",
        "  intel_raw = np.nanmean(my_intel[my_var][:first_nyears])\n",
        "  #std_ratio = np.std(my_run[my_var][div_year:])/np.std(my_run[my_var][:div_year])\n",
        "  vmin = np.nanmin(np.hstack((ten_yr_intel,ten_yr_test)))\n",
        "  vmax = np.nanmax(np.hstack((ten_yr_intel,ten_yr_test)))\n",
        "  nbins = 16\n",
        "  bins = np.linspace(vmin,vmax,nbins)\n",
        "  ax.hist(ten_yr_intel,bins,color = 'k',label = 'Intel',alpha = 0.4,density = True)\n",
        "  ax.hist(ten_yr_test,bins,color = 'orange',label = my_test,alpha = 0.4,density = True)\n",
        "  #ax.set_title('Mean')\n",
        "  #p = plt.hist(mean_intel,bins=bins)[0]\n",
        "  #q = plt.hist(mean_test,bins=bins)[0]\n",
        "  #p = p/p.sum(axis=0, keepdims=True) \n",
        "  #q = q/q.sum(axis=0, keepdims=True) \n",
        "\n",
        "  #plt.hist(p,bins)\n",
        "  #plt.hist(q,bins)\n",
        "  ylim = plt.gca().get_ylim()\n",
        "  plt.vlines(intel_raw,0,ylim[1],linestyle = '--')\n",
        "  plt.vlines(test_raw,0,ylim[1],linestyle = '-.')\n",
        "  plt.xlabel(my_var)\n",
        "  if ivar < 3:\n",
        "    ax.xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.1f'))\n",
        "\n",
        "  #plt.xticks(ticks=4)\n",
        "  if ivar % 3 == 0:\n",
        "    plt.ylabel('Histogram')\n",
        "  if ivar == 8:\n",
        "    plt.legend()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjKhvtgq_bBI"
      },
      "source": [
        "intel_raw = np.nanmean(my_intel[my_var][:first_nyears])\n",
        "intel_raw\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPhX9zwD_Aer"
      },
      "source": [
        "df.Simulation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbPlrMprkHxC"
      },
      "source": [
        "### Shuffle Intel\n",
        "my_test = 'rh-min-low'\n",
        "my_run = df[(df.Simulation == my_test)]\n",
        "\n",
        "\n",
        "fig = plt.figure(1,figsize = (12,6))\n",
        "mean_intel = []\n",
        "std_intel = []\n",
        "nyear = 100\n",
        "use_year = 100\n",
        "my_var = 'BURDEN2'\n",
        "intel_df = df[df.Label == 'Intel']\n",
        "nshuffle = 10\n",
        "div_year = int(use_year/2)\n",
        "\n",
        "for my_simu in np.unique(intel_df.Simulation):\n",
        "  intel_ts = np.array(intel_df[(intel_df.Simulation == my_simu) & (intel_df.nyear >= nyear - use_year)][my_var])\n",
        "  for ishuffle in range(nshuffle):\n",
        "    np.random.shuffle(intel_ts)\n",
        "    new_ts = intel_ts.copy()\n",
        "    \n",
        "    mean_intel.append(np.nanmean(new_ts[:div_year])/np.nanmean(new_ts[div_year:]))\n",
        "    std_intel.append(np.nanstd(new_ts[:div_year])/np.nanstd(new_ts[div_year:]))\n",
        "\n",
        "### Shuffle rh-min-low\n",
        "mean_test = []\n",
        "std_test = []\n",
        "rh_ts = np.array(my_run[my_var])\n",
        "print(rh_ts)\n",
        "for ishuffle in range(1000):\n",
        "  np.random.shuffle(rh_ts)\n",
        "  new_ts = rh_ts.copy()\n",
        "  mean_test.append(np.nanmean(new_ts[:div_year])/np.nanmean(new_ts[div_year:]))\n",
        "  std_test.append(np.nanstd(new_ts[:div_year])/np.nanstd(new_ts[div_year:]))\n",
        "\n",
        "### plot figures\n",
        "ax = plt.subplot(1,2,1)\n",
        "mean_ratio = np.mean(my_run[my_var][div_year:])/np.mean(my_run[my_var][:div_year])\n",
        "std_ratio = np.std(my_run[my_var][div_year:])/np.std(my_run[my_var][:div_year])\n",
        "vmin = np.nanmin(np.hstack((mean_intel,mean_test)))\n",
        "vmax = np.nanmax(np.hstack((mean_intel,mean_test)))\n",
        "nbins = 16\n",
        "bins = np.linspace(vmin,vmax,nbins)\n",
        "ax.hist(mean_intel,bins,color = 'b',label = 'Intel',alpha = 0.4,density = True)\n",
        "ax.hist(mean_test,bins,color = 'orange',label = my_test,alpha = 0.4,density = True)\n",
        "ax.set_title('Mean')\n",
        "#p = plt.hist(mean_intel,bins=bins)[0]\n",
        "#q = plt.hist(mean_test,bins=bins)[0]\n",
        "#p = p/p.sum(axis=0, keepdims=True) \n",
        "#q = q/q.sum(axis=0, keepdims=True) \n",
        "\n",
        "#plt.hist(p,bins)\n",
        "#plt.hist(q,bins)\n",
        "ylim = plt.gca().get_ylim()\n",
        "plt.vlines(mean_ratio,0,ylim[1],linestyle = '--')\n",
        "\n",
        "\n",
        "ax = plt.subplot(1,2,2)\n",
        "vmin = np.nanmin(np.hstack((std_intel,std_test)))\n",
        "vmax = np.nanmax(np.hstack((std_intel,std_test)))\n",
        "ax.set_title('Stddev')\n",
        "#bins = np.linspace(vmin,vmax,nbins)\n",
        "\n",
        "bins = np.logspace(np.log(vmin),np.log(vmax),nbins)\n",
        "plt.xscale('log')\n",
        "\n",
        "\n",
        "ax.hist(std_intel,bins,color = 'b',label = 'Intel',alpha = 0.4,density = True)\n",
        "ax.hist(std_test,bins,color = 'orange',label = my_test,alpha = 0.4,density = True)\n",
        "ylim = plt.gca().get_ylim()\n",
        "plt.vlines(std_ratio,0,ylim[1],linestyle = '--')\n",
        "\n",
        "plt.legend()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNUloOGCQavy"
      },
      "source": [
        "### How many variables fails the 5% KS-test in each year (or plot p-value across time)\n",
        "nyear = 100\n",
        "var_list = ['TS','TSMN','TSMX','VT','VU','U10','LWCF','BURDEN2','CCN3']\n",
        "\n",
        "confidence_level = 0.05\n",
        "zscore_ts = np.zeros((len(test_list),len(var_list),nyear))\n",
        "std_intel_ts = np.zeros((len(test_list),len(var_list),nyear))\n",
        "std_gnu_ts = np.zeros((len(test_list),len(var_list),nyear))\n",
        "gnu_df = df[df.Label == 'GNU']\n",
        "\n",
        "for itest, my_test in enumerate(test_list):\n",
        "  for yr in range(nyear):\n",
        "    num_fail = 0\n",
        "    for ivar,my_var in enumerate(var_list):\n",
        "      x1 = intel_df[(intel_df.nyear == yr)][my_var]\n",
        "      x2 = gnu_df[(gnu_df.nyear == yr)][my_var]\n",
        "      y = df[(df.Simulation.str.contains(my_test)) & (df.nyear == yr)][my_var]\n",
        "      z_score = (y - x1.mean())/x1.std()\n",
        "      std_intel_ts[itest,ivar,yr] = x1.std()\n",
        "      std_gnu_ts[itest,ivar,yr] = x2.std()\n",
        "      zscore_ts[itest,ivar,yr] = z_score\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNnPeP8Hm4i2"
      },
      "source": [
        "\n",
        "zscore_intel = np.zeros((2,len(var_list),nyear)) # Dim 0: upper limit for 0, and lower limit for 1\n",
        "\n",
        "for yr in range(nyear):\n",
        "  for ivar,my_var in enumerate(var_list):\n",
        "    x1 = intel_df[(intel_df.nyear == yr)][my_var]\n",
        "    #x2 = gnu_df[(gnu_df.nyear == yr)][my_var]\n",
        "    for isimu, my_quant in enumerate([0.975,0.025]):\n",
        "      y = x1.quantile(my_quant)\n",
        "      z_score = (y - x1.mean())/x1.std()\n",
        "      zscore_intel[isimu,ivar,yr] = z_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZREy9iEe6OlR"
      },
      "source": [
        "itest = 0\n",
        "zscore_table = pd.DataFrame(columns =  var_list)\n",
        "for itest,my_test in enumerate(test_list):\n",
        "  for irow,all_year in enumerate([1,10,50,100]):\n",
        "    empty_array = np.zeros(len(var_list))\n",
        "    for ivar, my_var in enumerate(var_list):\n",
        "      #empty_array[ivar] = round(np.mean(abs(zscore_ts[itest,ivar,:nyear])),3)\n",
        "      empty_array[ivar] = round(np.mean((zscore_ts[itest,ivar,:all_year])),3)\n",
        "    one_line = pd.DataFrame(columns = var_list, data = empty_array.reshape(1,9))\n",
        "    one_line['nyear'] = int(all_year)\n",
        "    one_line['Simulation'] = test_list[itest]\n",
        "    \n",
        "    zscore_table = zscore_table.append(one_line,ignore_index = True)\n",
        "zscore_table.set_index(['Simulation','nyear']).reindex(columns = var_list) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJSsisRUAPOf"
      },
      "source": [
        "itest= 0\n",
        "idx = 0\n",
        "plt.figure(1,figsize = (12,8))\n",
        "#for itest,my_test in enumerate(test_list):\n",
        "sns.lineplot(range(nyear),abs(zscore_ts[itest,idx,:]),label = test_list[itest])\n",
        "plt.hlines([0],0,100,linestyle = '--')\n",
        "plt.xlabel(\"Years\",fontsize = fs)\n",
        "plt.ylabel(\"Z-score\",fontsize = fs)\n",
        "plt.legend(frameon=False,fontsize = fs)\n",
        "plt.title(var_list[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEHcft7_IUBM"
      },
      "source": [
        "fig = plt.figure(1,figsize = (8,8))\n",
        "itest0 = 1\n",
        "idx0 = 0\n",
        "idx1 = 6\n",
        "fs = 14\n",
        "sns.kdeplot(zscore_ts[itest0,idx0,:],zscore_ts[itest0,idx1,:],shade = True)\n",
        "plt.xlabel('Z-score '+var_list[idx0],fontsize = fs)\n",
        "plt.ylabel('Z-score '+var_list[idx1],fontsize = fs)\n",
        "\n",
        "plt.scatter(zscore_ts[itest0,idx0,0],zscore_ts[itest0,idx1,0],marker= 'o',c = 'r')\n",
        "xlim = plt.gca().get_xlim()\n",
        "ylim = plt.gca().get_ylim()\n",
        "\n",
        "plt.hlines([0],xlim[0],xlim[1],linestyle = '--')\n",
        "plt.vlines([0],ylim[0],ylim[1],linestyle = '--')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbpJVtVLycze"
      },
      "source": [
        "fig = plt.figure(1,figsize = (8,8))\n",
        "itest0 = 1\n",
        "idx0 = 0\n",
        "idx1 = 6\n",
        "fs = 14\n",
        "sns.kdeplot(zscore_ts[itest0,idx0,:],zscore_ts[itest0,idx1,:],shade = True)\n",
        "plt.xlabel('Z-score '+var_list[idx0],fontsize = fs)\n",
        "plt.ylabel('Z-score '+var_list[idx1],fontsize = fs)\n",
        "\n",
        "all_year = 1\n",
        "\n",
        "for itest0,my_test,my_marker, my_color in zip(range(8),test_list,['o','o','o','o','*','*','*','*'],['k','r','b','g','k','r','b','g']):\n",
        "  plt.scatter(np.mean(zscore_ts[itest0,idx0,:all_year]),np.mean(zscore_ts[itest0,idx1,:all_year]),marker= my_marker,c = my_color)\n",
        "xlim = plt.gca().get_xlim()\n",
        "ylim = plt.gca().get_ylim()\n",
        "\n",
        "plt.hlines([0],xlim[0],xlim[1],linestyle = '--')\n",
        "plt.vlines([0],ylim[0],ylim[1],linestyle = '--')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGm_UDDnJnvS"
      },
      "source": [
        "\n",
        "### 9 subplots: How do standard deviation evolve in Intel ensemble?\n",
        "### Z scores changing with year\n",
        "normalize_y = False\n",
        "use_year = 100\n",
        "nrow = 3\n",
        "ncol = 3\n",
        "fig = plt.figure(figsize=(12,12))\n",
        "plt.subplots_adjust(wspace = 0.4,hspace= 0.3)\n",
        "\n",
        "#fig = plt.figure(figsize=(8,8))\n",
        "\n",
        "plt.tight_layout()\n",
        "# Set to True to use only 25 simulations \n",
        "nyear =100\n",
        "\n",
        "for irow in range(nrow):\n",
        "  for icol in range(ncol):\n",
        "    idx = ncol*irow+icol\n",
        "    ax = plt.subplot(nrow,ncol,idx+1)\n",
        "    my_var = var_list[idx]\n",
        "    #for itest,my_test in enumerate(test_list):\n",
        "    itest = 0\n",
        "    plt.plot(range(nyear),std_intel_ts[itest,idx,:],label = 'Intel')\n",
        "    plt.plot(range(nyear),std_gnu_ts[itest,idx,:],label = 'GNU')\n",
        "    if irow == 2:\n",
        "      plt.xlabel('Year',fontsize = fs)\n",
        "    if icol == 0:\n",
        "      plt.ylabel('Internal Variability',fontsize=fs)\n",
        "    plt.title(my_var)\n",
        "    if irow == 0 and icol == 2:\n",
        "      ax.legend(frameon=False)\n",
        "\n",
        "### Plot z-score for test runs\n",
        "fig = plt.figure(2,figsize=(12,12))\n",
        "plt.subplots_adjust(wspace = 0.4,hspace= 0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "# Set to True to use only 25 simulations \n",
        "\n",
        "\n",
        "for irow in range(nrow):\n",
        "  for icol in range(ncol):\n",
        "    idx = ncol*irow+icol\n",
        "    ax = plt.subplot(nrow,ncol,idx+1)\n",
        "    my_var = var_list[idx]\n",
        "    #for itest,my_test in enumerate(test_list):\n",
        "    itest0 = 0\n",
        "    itest1 = 1\n",
        "    plt.plot(range(nyear),zscore_ts[itest0,idx,:],label = test_list[itest0])\n",
        "    plt.plot(range(nyear),zscore_ts[itest1,idx,:],label = test_list[itest1])\n",
        "    plt.xlabel('Year')\n",
        "    plt.ylabel('Z-score')\n",
        "    plt.title(my_var)\n",
        "    upper = 0.975\n",
        "    lower = 0.025\n",
        "    up_limit = zscore_intel[0,idx]\n",
        "    lw_limit = zscore_intel[1,idx]\n",
        "    #plt.plot(range(nyear),up_limit,linestyle = '--',color='k')\n",
        "    #plt.plot(range(nyear),lw_limit,linestyle = '--',color='k')\n",
        "    if irow == 0 and icol == 2:\n",
        "      ax.legend(frameon=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEtMyQ-wNQXj"
      },
      "source": [
        "### 9 subplots\n",
        "normalize_y = False\n",
        "abs_value = True # Set to True to use absolute z-score\n",
        "nrow = 3\n",
        "ncol = 3\n",
        "fig = plt.figure(figsize=(12,12))\n",
        "plt.subplots_adjust(wspace = 0.4,hspace= 0.3)\n",
        "\n",
        "#fig = plt.figure(figsize=(8,8))\n",
        "\n",
        "plt.tight_layout()\n",
        "# Set to True to use only 25 simulations \n",
        "\n",
        "\n",
        "for irow in range(nrow):\n",
        "  for icol in range(ncol):\n",
        "    idx = ncol*irow+icol\n",
        "    ax = plt.subplot(nrow,ncol,idx+1)\n",
        "    my_var = var_list[idx]\n",
        "    #for itest,my_test in enumerate(test_list):\n",
        "    #itest = 0\n",
        "    for itest in [0,7]:\n",
        "      if abs_value:\n",
        "        plt.plot(range(nyear),abs(zscore_ts[itest,idx,:]),label = test_list[itest])\n",
        "        #plt.ylim([-0.5,4.2])\n",
        "        plt.locator_params(axis='y', nbins=5)\n",
        "\n",
        "      else:\n",
        "        plt.plot(range(nyear),(zscore_ts[itest,idx,:]),label = test_list[itest])\n",
        "        plt.ylim([-3.5,3.5])\n",
        "\n",
        "      plt.hlines([0],0,100,linestyle = '--')\n",
        "      plt.xlabel('Year')\n",
        "      plt.ylabel('Z-score')\n",
        "      plt.title(my_var)\n",
        "      if irow == 0 and icol == 2:\n",
        "        ax.legend(frameon=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIS_QtO_kYi-"
      },
      "source": [
        "#### Same standard deviation and mean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f1mWGnrkeEA"
      },
      "source": [
        " To derive for Z-score of each test run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axal3eFFisCl"
      },
      "source": [
        "### 9 subplots, Z-scores that derived based on 100 year mean and standard deviation of Intel ensemble\n",
        "\n",
        "\n",
        "'''\n",
        "confidence_level = 0.05\n",
        "zscore_ts = np.zeros((len(test_list),len(var_list),nyear))\n",
        "for ivar,my_var in enumerate(var_list):\n",
        "  x1 = intel_df[my_var]\n",
        "  for itest, my_test in enumerate(test_list):\n",
        "    for yr in range(nyear):\n",
        "      y = df[(df.Simulation.str.contains(my_test)) & (df.nyear == yr)][my_var]\n",
        "      z_score = (y - x1.mean())/x1.std()     \n",
        "      zscore_ts[itest,ivar,yr] = z_score\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap3iRcgKkXl0"
      },
      "source": [
        "'''\n",
        "normalize_y = False\n",
        "abs_value = False # Set to True to use absolute z-score\n",
        "nrow = 3\n",
        "ncol = 3\n",
        "\n",
        "fig = plt.figure(figsize=(12,12))\n",
        "plt.subplots_adjust(wspace = 0.4,hspace= 0.3)\n",
        "\n",
        "#fig = plt.figure(figsize=(8,8))\n",
        "\n",
        "plt.tight_layout()\n",
        "for irow in range(nrow):\n",
        "  for icol in range(ncol):\n",
        "    idx = ncol*irow+icol\n",
        "    ax = plt.subplot(nrow,ncol,idx+1)\n",
        "    my_var = var_list[idx]\n",
        "    #for itest,my_test in enumerate(test_list):\n",
        "    #itest = 0\n",
        "    for itest in [0,7]:\n",
        "      if abs_value:\n",
        "        plt.plot(range(nyear),abs(zscore_ts[itest,idx,:]),label = test_list[itest])\n",
        "        #plt.ylim([-0.5,4.2])\n",
        "        plt.locator_params(axis='y', nbins=5)\n",
        "\n",
        "      else:\n",
        "        plt.plot(range(nyear),(zscore_ts[itest,idx,:]),label = test_list[itest])\n",
        "        #plt.ylim([-3.5,3.5])\n",
        "\n",
        "      plt.hlines([0],0,100,linestyle = '--')\n",
        "      plt.xlabel('Year')\n",
        "      plt.ylabel('Z-score')\n",
        "      plt.title(my_var)\n",
        "      if irow == 0 and icol == 2:\n",
        "        ax.legend(frameon=False)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKlRpid2oaB6"
      },
      "source": [
        "#np.argwhere(zscore_ts[:,:,0] == np.max(zscore_ts[:,:,0]))\n",
        "variance_ratio = np.zeros((len(var_list),len(np.unique(intel_df.Simulation))))\n",
        "for isimu, my_simu in enumerate(np.unique(intel_df.Simulation)):\n",
        "  newdf = intel_df[(intel_df.Simulation == my_simu)]\n",
        "  for ivar, my_var in enumerate(var_list):\n",
        "    variance_ratio[ivar,isimu] = (newdf[newdf.nyear >= 50][my_var].std())/(newdf[newdf.nyear < 50][my_var].std())\n",
        "\n",
        "test_variance_ratio = np.zeros((len(var_list),8))\n",
        "for isimu, my_simu in enumerate(test_list):\n",
        "  newdf = df[df.Simulation == test_list[isimu]]\n",
        "  for ivar, my_var in enumerate(var_list):\n",
        "    test_variance_ratio[ivar,isimu] = (newdf[newdf.nyear >= 50][my_var].std())/(newdf[newdf.nyear < 50][my_var].std())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM9Y_9IOAIBP"
      },
      "source": [
        "test_variance_ratio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlmtrJGz9sMX"
      },
      "source": [
        "idx = 3\n",
        "itest = 1\n",
        "plt.hist(variance_ratio[idx,:])\n",
        "\n",
        "\n",
        "\n",
        "print(test_variance_ratio[idx,itest])\n",
        "\n",
        "for idx,my_var in enumerate(var_list):\n",
        "  for itest,my_test in enumerate(test_list):\n",
        "    if test_variance_ratio[idx,itest] < np.quantile(variance_ratio[idx,:],0.025) or test_variance_ratio[idx,itest] > np.quantile(variance_ratio[idx,:],0.975):\n",
        "      print('This is '+str(my_var)+','+str(my_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7U-xbOlC4Sc"
      },
      "source": [
        "fig = plt.figure(figsize=(10,6))\n",
        "ax2 = plt.subplot()\n",
        "ax2.set_title('Ratio of standard deviation (Second half/First half)')\n",
        "data = [variance_ratio[idx,:] for idx in range(9)]\n",
        "ax2.boxplot(data, notch=True,showfliers=True,labels = var_list)\n",
        "for idx, my_var in enumerate(var_list):\n",
        "  ax2.scatter(idx+1,test_variance_ratio[idx,7],marker = 'o',c= 'r')\n",
        "\n",
        "#sns.boxplot(variance_ratio[:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyrqr6jyfaVD"
      },
      "source": [
        "idx = 0\n",
        "itest = 1\n",
        "yr_len = 50\n",
        "bins = np.linspace(-3,3,20)\n",
        "plt.hist(zscore_ts[itest,idx,:yr_len],bins = bins, density = True,alpha = 0.3,label = 'First half')#histtype='step')\n",
        "plt.hist(zscore_ts[itest,idx,-yr_len:],bins = bins, density = True,alpha= 0.3,label = 'Second half')#,histtype='step')\n",
        "\n",
        "plt.vlines(zscore_ts[itest,idx,1], 0, 0.4, linestyle = '--')\n",
        "plt.legend(frameon=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjLTg099pA85"
      },
      "source": [
        "#### Correlation coefficients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2TIjzKwGFGJ"
      },
      "source": [
        "Same variable, across simulations. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aycbbbzv0rCe"
      },
      "source": [
        "var_df\n",
        "new_var_df = var_df.sort_values(by='type').reset_index()\n",
        "new_var_df\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}